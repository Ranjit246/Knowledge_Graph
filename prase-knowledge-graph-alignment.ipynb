{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-25T09:30:28.652869Z","iopub.execute_input":"2022-12-25T09:30:28.654514Z","iopub.status.idle":"2022-12-25T09:30:28.685630Z","shell.execute_reply.started":"2022-12-25T09:30:28.654381Z","shell.execute_reply":"2022-12-25T09:30:28.684681Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class Entity:\n    def __init__(self, idx: int, name: str, preprocess_func, is_literal=False, affiliation=None):\n        self._is_literal = is_literal\n\n        self.id: int = idx\n        self.name: str = name.strip()\n        self.value = None\n\n        self.preprocess_func = preprocess_func\n        self.affiliation = affiliation\n\n        self.involved_as_tail_dict = dict()\n        self.involved_as_head_dict = dict()\n\n        self.embedding = None\n\n        self.__init()\n\n    @staticmethod\n    def is_entity():\n        return True\n\n    @staticmethod\n    def is_relation():\n        return False\n\n    def __init(self):\n        self.value = self.preprocess_func(self.name)\n\n    def is_literal(self):\n        return self._is_literal\n\n    def add_relation_as_head(self, relation, tail):\n        if self.involved_as_head_dict.__contains__(relation) is False:\n            self.involved_as_head_dict[relation] = set()\n        self.involved_as_head_dict[relation].add(tail)\n\n    def add_relation_as_tail(self, relation, head):\n        if self.involved_as_tail_dict.__contains__(relation) is False:\n            self.involved_as_tail_dict[relation] = set()\n        self.involved_as_tail_dict[relation].add(head)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:47:44.714811Z","iopub.execute_input":"2022-12-25T09:47:44.715236Z","iopub.status.idle":"2022-12-25T09:47:44.725549Z","shell.execute_reply.started":"2022-12-25T09:47:44.715199Z","shell.execute_reply":"2022-12-25T09:47:44.724398Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\nclass Relation:\n    def __init__(self, idx: int, name: str, preprocess_func, is_attribute=False, affiliation=None):\n        self._is_attribute = is_attribute\n\n        self.id: int = idx\n        self.name: str = name.strip()\n        self.value = None\n\n        self.preprocess_func = preprocess_func\n        self.affiliation = affiliation\n\n        self.frequency = 0\n\n        self.head_ent_set = set()\n        self.tail_ent_set = set()\n        self.tuple_set = set()\n\n        self.functionality = 0.0\n        self.functionality_inv = 0.0\n\n        self.embedding = None\n        self.__init()\n\n    @staticmethod\n    def is_entity():\n        return False\n\n    @staticmethod\n    def is_relation():\n        return True\n\n    def __init(self):\n        self.value = self.preprocess_func(self.name)\n\n    def is_attribute(self):\n        return self._is_attribute\n\n    def add_relation_tuple(self, head, tail):\n        self.head_ent_set.add(head)\n        self.tail_ent_set.add(tail)\n        self.tuple_set.add((head, tail))\n        self.frequency += 1\n\n    def calculate_functionality(self):\n        if self.frequency == 0:\n            return\n        self.functionality = len(self.head_ent_set) / self.frequency\n        self.functionality_inv = len(self.tail_ent_set) / self.frequency","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:48:03.286326Z","iopub.execute_input":"2022-12-25T09:48:03.286747Z","iopub.status.idle":"2022-12-25T09:48:03.297484Z","shell.execute_reply.started":"2022-12-25T09:48:03.286711Z","shell.execute_reply":"2022-12-25T09:48:03.296507Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:48:30.701461Z","iopub.execute_input":"2022-12-25T09:48:30.701854Z","iopub.status.idle":"2022-12-25T09:48:30.707520Z","shell.execute_reply.started":"2022-12-25T09:48:30.701824Z","shell.execute_reply":"2022-12-25T09:48:30.706320Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class KG:\n    def __init__(self, name=\"KG\", ent_pre_func=None, rel_pre_func=None, attr_pre_func=None,\n                 lite_pre_func=None):\n        self.name = name\n        self.ent_pre_func = ent_pre_func\n        self.rel_pre_func = rel_pre_func\n        self.attr_pre_func = attr_pre_func\n        self.lite_pre_func = lite_pre_func\n\n        self.entity_set = set()\n        self.relation_set = set()\n        self.attribute_set = set()\n        self.literal_set = set()\n\n        self.entity_dict_by_name = dict()\n        self.relation_dict_by_name = dict()\n        self.attribute_dict_by_name = dict()\n        self.literal_dict_by_name = dict()\n\n        self.entity_dict_by_value = dict()\n        self.relation_dict_by_value = dict()\n        self.attribute_dict_by_value = dict()\n        self.literal_dict_by_value = dict()\n\n        self.ent_lite_list_by_id = list()\n        self.rel_attr_list_by_id = list()\n\n        self.relation_tuple_list = list()\n        self.attribute_tuple_list = list()\n\n        self.functionality_dict = dict()\n        self.ent_id_list = list()\n        self.fact_dict_by_head = dict()\n        self.fact_dict_by_tail = dict()\n        self.is_literal_list = list()\n\n        self.ent_embeddings = None\n\n        self.__init()\n        self._init = False\n\n    def __init(self):\n        if self.ent_pre_func is None:\n            self.ent_pre_func = self.default_pre_func\n        if self.rel_pre_func is None:\n            self.rel_pre_func = self.default_pre_func\n        if self.attr_pre_func is None:\n            self.attr_pre_func = self.default_pre_func\n        if self.lite_pre_func is None:\n            self.lite_pre_func = self.default_pre_func_for_literal\n\n    @staticmethod\n    def default_pre_func(name: str):\n        pattern = r'\"?<?([^\">]*)>?\"?.*'\n        matchObj = re.match(pattern=pattern, string=name)\n        if matchObj is None:\n            print(\"Match Error: \" + name)\n            return name\n        value = matchObj.group(1).strip()\n        if \"/\" in value:\n            value = value.split(sep=\"/\")[-1].strip()\n        return value\n\n    @staticmethod\n    def default_pre_func_for_literal(name: str):\n        value = name.split(\"^\")[0].strip()\n        start, end = 0, len(value) - 1\n        if start < len(value) and value[start] == '<':\n            start += 1\n        if end > 0 and value[end] == '>':\n            end -= 1\n        if start < len(value) and value[start] == '\"':\n            start += 1\n        if end > 0 and value[end] == '\"':\n            end -= 1\n        if start > end:\n            print(\"Match Error: \" + name)\n            return name\n        value = value[start: end + 1].strip()\n        return value\n\n    @staticmethod\n    def __dict_set_insert_helper(dictionary: dict, key, value):\n        if dictionary.__contains__(key) is False:\n            dictionary[key] = set()\n        dictionary[key].add(value)\n\n    def get_entity(self, name: str):\n        if self.entity_dict_by_name.__contains__(name):\n            return self.entity_dict_by_name.get(name)\n        else:\n            entity = Entity(idx=len(self.literal_set) + len(self.entity_set), name=name, preprocess_func=self.ent_pre_func, affiliation=self)\n            self.entity_set.add(entity)\n            self.entity_dict_by_name[entity.name] = entity\n            self.entity_dict_by_value[entity.value] = entity\n            # self.entity_dict_by_id[entity.id] = entity\n            # self.ent_id_list.append(entity.id)\n            # self.is_literal_list.append(False)\n            return entity\n\n    def get_relation(self, name: str):\n        if self.relation_dict_by_name.__contains__(name):\n            return self.relation_dict_by_name.get(name)\n        else:\n            relation = Relation(idx=len(self.attribute_set) + len(self.relation_set), name=name, preprocess_func=self.rel_pre_func,\n                                affiliation=self)\n            self.relation_set.add(relation)\n            self.relation_dict_by_name[relation.name] = relation\n            self.relation_dict_by_value[relation.value] = relation\n            # self.relation_dict_by_id[relation.id] = relation\n            return relation\n\n    def get_attribute(self, name: str):\n        if self.attribute_dict_by_name.__contains__(name):\n            return self.attribute_dict_by_name.get(name)\n        else:\n            attribute = Relation(idx=len(self.attribute_set) + len(self.relation_set), name=name, preprocess_func=self.attr_pre_func,\n                                 affiliation=self, is_attribute=True)\n            self.attribute_set.add(attribute)\n            self.attribute_dict_by_name[attribute.name] = attribute\n            self.attribute_dict_by_value[attribute.value] = attribute\n            # self.relation_dict_by_id[attribute.id] = attribute\n            return attribute\n\n    def get_literal(self, name: str):\n        if self.literal_dict_by_name.__contains__(name):\n            return self.literal_dict_by_name.get(name)\n        else:\n            literal = Entity(idx=len(self.literal_set) + len(self.entity_set), name=name, preprocess_func=self.lite_pre_func,\n                             affiliation=self, is_literal=True)\n            self.literal_set.add(literal)\n            self.literal_dict_by_name[literal.name] = literal\n            self.literal_dict_by_value[literal.value] = literal\n            # self.entity_dict_by_id[literal.id] = literal\n            # self.is_literal_list.append(True)\n            return literal\n\n    def insert_relation_tuple(self, head: str, relation: str, tail: str):\n        ent_h, rel, ent_t = self.get_entity(head), self.get_relation(relation), self.get_entity(tail)\n        self.__insert_relation_tuple_one_way(ent_h, rel, ent_t)\n        relation_inv = relation.strip() + str(\"-(INV)\")\n        rel_v = self.get_relation(relation_inv)\n        self.__insert_relation_tuple_one_way(ent_t, rel_v, ent_h)\n\n    def insert_attribute_tuple(self, entity: str, attribute: str, literal: str):\n        ent, attr, val = self.get_entity(entity), self.get_attribute(attribute), self.get_literal(literal)\n        self.__insert_attribute_tuple_one_way(ent, attr, val)\n        attribute_inv = attribute.strip() + str(\"-(INV)\")\n        attr_v = self.get_attribute(attribute_inv)\n        self.__insert_attribute_tuple_one_way(val, attr_v, ent)\n\n    def __insert_relation_tuple_one_way(self, ent_h, rel, ent_t):\n        ent_h.add_relation_as_head(relation=rel, tail=ent_t)\n        rel.add_relation_tuple(head=ent_h, tail=ent_t)\n        ent_t.add_relation_as_tail(relation=rel, head=ent_h)\n        self.relation_tuple_list.append((ent_h, rel, ent_t))\n        # if not self.fact_dict_by_head.__contains__(ent_h.id):\n        #     self.fact_dict_by_head[ent_h.id] = list()\n        # if not self.fact_dict_by_tail.__contains__(ent_t.id):\n        #     self.fact_dict_by_tail[ent_t.id] = list()\n        # self.fact_dict_by_head[ent_h.id].append((rel.id, ent_t.id))\n        # self.fact_dict_by_tail[ent_t.id].append((rel.id, ent_h.id))\n\n    def __insert_attribute_tuple_one_way(self, ent, attr, val):\n        ent.add_relation_as_head(relation=attr, tail=val)\n        attr.add_relation_tuple(head=ent, tail=val)\n        val.add_relation_as_tail(relation=attr, head=ent)\n        self.attribute_tuple_list.append((ent, attr, val))\n        # if not self.fact_dict_by_head.__contains__(ent.id):\n        #     self.fact_dict_by_head[ent.id] = list()\n        # if not self.fact_dict_by_tail.__contains__(val.id):\n        #     self.fact_dict_by_tail[val.id] = list()\n        # self.fact_dict_by_head[ent.id].append((attr.id, val.id))\n        # self.fact_dict_by_tail[val.id].append((attr.id, ent.id))\n\n    def get_object_by_name(self, name: str):\n        name = name.strip()\n        if self.attribute_dict_by_name.__contains__(name):\n            return self.attribute_dict_by_name[name]\n        if self.relation_dict_by_name.__contains__(name):\n            return self.relation_dict_by_name[name]\n        if self.literal_dict_by_name.__contains__(name):\n            return self.literal_dict_by_name[name]\n        if self.entity_dict_by_name.__contains__(name):\n            return self.entity_dict_by_name[name]\n\n    def __calculate_functionality(self):\n        for relation in self.relation_set:\n            relation.calculate_functionality()\n            self.functionality_dict[relation.id] = relation.functionality\n        for attribute in self.attribute_set:\n            attribute.calculate_functionality()\n            self.functionality_dict[attribute.id] = attribute.functionality\n\n    def init(self):\n        def init_index(set_a, set_b):\n            index = 0\n            for item in set_a:\n                item.id = index\n                index += 1\n            for item in set_b:\n                item.id = index\n                index += 1\n\n        def init_fact_dict(tuple_list, fact_dict_by_head, fact_dict_by_tail):\n            for (h, r, t) in tuple_list:\n                if not self.fact_dict_by_head.__contains__(h.id):\n                    self.fact_dict_by_head[h.id] = list()\n                if not self.fact_dict_by_tail.__contains__(t.id):\n                    self.fact_dict_by_tail[t.id] = list()\n                fact_dict_by_head[h.id].append((r.id, t.id))\n                fact_dict_by_tail[t.id].append((r.id, h.id))\n\n        def init_idx_dict(item_set):\n            idx_list = [None for _ in range(len(item_set))]\n            for item in item_set:\n                idx_list[item.id] = item\n            return idx_list\n\n        init_index(self.entity_set, self.literal_set)\n        init_index(self.relation_set, self.attribute_set)\n        init_fact_dict(self.relation_tuple_list + self.attribute_tuple_list, self.fact_dict_by_head, self.fact_dict_by_tail)\n        self.ent_lite_list_by_id = init_idx_dict(self.entity_set | self.literal_set)\n        self.rel_attr_list_by_id = init_idx_dict(self.relation_set | self.attribute_set)\n        self.is_literal_list = [False for _ in range(len(self.entity_set))] + [True for _ in range(len(self.literal_set))]\n        self.ent_id_list = [item.id for item in self.entity_set]\n        self.__calculate_functionality()\n        self._init = True\n\n    def is_init(self):\n        return self._init\n\n    def init_ent_embeddings(self):\n        for ent in self.entity_set:\n            idx, embedding = ent.id, ent.embedding\n            if embedding is None:\n                break\n            if self.ent_embeddings is None:\n                self.ent_embeddings = np.zeros((len(self.entity_set), len(embedding)))\n            self.ent_embeddings[idx, :] = embedding\n\n    def set_ent_embedding(self, idx, emb, func=None):\n        if self.ent_embeddings is not None:\n            if func is None:\n                self.ent_embeddings[idx, :] = emb\n            else:\n                self.ent_embeddings[idx, :] = func(self.ent_lite_list_by_id[idx].embedding, emb)\n\n    def print_kg_info(self, func_num=10):\n        print(\"\\nInformation of Knowledge Graph (\" + str(self.name) + \"):\")\n        print(\"- Relation Tuple Number: \" + str(int(len(self.relation_tuple_list) / 2)))\n        print(\"- Attribute Tuple Number: \" + str(int(len(self.attribute_tuple_list) / 2)))\n        print(\"- Entity Number: \" + str(len(self.entity_set)))\n        print(\"- Relation Number: \" + str(int(len(self.relation_set) / 2)))\n        print(\"- Attribute Number: \" + str(int(len(self.attribute_set) / 2)))\n        print(\"- Literal Number: \" + str(len(self.literal_set)))\n        print(\"- Functionality Statistics:\")\n\n        def functionality_printer(is_rel: bool, inverse: bool, num: int):\n            if is_rel:\n                tmp_list = list(self.relation_set.copy())\n            else:\n                tmp_list = list(self.attribute_set.copy())\n            if inverse:\n                tmp_list.sort(key=lambda x: x.functionality_inv, reverse=True)\n            else:\n                tmp_list.sort(key=lambda x: x.functionality, reverse=True)\n            title = \"--- TOP-{} {} ({}) ---\"\n            title = title.format(str(num), \"Relations\" if is_rel else \"Attributes\", \"Func-Inv\" if inverse else \"Func\")\n            print(title)\n            for i in range(min(num, len(tmp_list))):\n                relation = tmp_list[i]\n                item = \"Name: {}\\t{}: {}\".format(relation.name, \"Func-Inv\" if inverse else \"Func\",\n                                                 relation.functionality_inv if inverse else relation.functionality)\n                print(item)\n            print(\"......\")\n\n        functionality_printer(True, False, func_num)\n        functionality_printer(True, True, func_num)\n        functionality_printer(False, False, func_num)\n        functionality_printer(False, True, func_num)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:49:23.366861Z","iopub.execute_input":"2022-12-25T09:49:23.367270Z","iopub.status.idle":"2022-12-25T09:49:23.427228Z","shell.execute_reply.started":"2022-12-25T09:49:23.367237Z","shell.execute_reply":"2022-12-25T09:49:23.425840Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_counterpart_id_and_prob(ent_match, ent_prob, ent_id):\n    counterpart = ent_match[ent_id]\n    if counterpart is None:\n        return None, 0.0\n    else:\n        return counterpart, ent_prob[ent_id]\n\n\ndef set_counterpart_id_and_prob(ent_match, ent_prob, ent_l_id, ent_r_id, prob):\n    curr_prob = ent_prob[ent_l_id]\n    if prob < curr_prob:\n        return\n    ent_match[ent_l_id], ent_prob[ent_l_id] = ent_r_id, prob\n\n\ndef register_rel_align_prob_norm(dictionary, rel, prob):\n    if not dictionary.__contains__(rel):\n        dictionary[rel] = 0.0\n    dictionary[rel] += prob\n\n\ndef register_ongoing_prob_product(dictionary, key1, key2, prob):\n    if not dictionary.__contains__(key1):\n        dictionary[key1] = dict()\n    if not dictionary[key1].__contains__(key2):\n        dictionary[key1][key2] = 0.0\n    dictionary[key1][key2] += prob\n\n\ndef get_rel_align_prob(dictionary, rel_l, rel_r):\n    if not dictionary.__contains__(rel_l):\n        return 0.0\n    if not dictionary[rel_l].__contains__(rel_r):\n        return 0.0\n    prob = dictionary[rel_l][rel_r]\n    prob = 1.0 if prob > 1.0 else prob\n    prob = 0.0 if prob < 0.0 else prob\n    return prob\n\n\ndef update_ent_align_prob(ent_align_ongoing_dict, ent_match, ent_prob, kg_l_ent_embeds, kg_r_ent_embeds, ent, fusion_func, init):\n    counterpart, value = None, 0.0\n    for (candidate, prob) in ent_align_ongoing_dict.items():\n        val = 1.0 - prob\n        if not init and kg_l_ent_embeds is not None and kg_r_ent_embeds is not None and fusion_func is not None:\n            ent_emb = kg_l_ent_embeds[ent, :]\n            candidate_emb = kg_r_ent_embeds[candidate, :]\n            val = fusion_func(val, ent_emb, candidate_emb)\n        if val >= value:\n            value, counterpart = val, candidate\n    value = 1.0 if value > 1.0 else value\n    value = 0.0 if value < 0.0 else value\n    set_counterpart_id_and_prob(ent_match, ent_prob, ent, counterpart, value)\n\n\ndef register_ent_equality(ent_align_ongoing_dict, rel_align_dict_l, rel_align_dict_r,\n                          kg_l_func, kg_r_func,\n                          rel, rel_counterpart, tail_counterpart,\n                          head_eqv_prob, theta, epsilon, delta, init):\n    prob_sub = get_rel_align_prob(rel_align_dict_l, rel, rel_counterpart) / epsilon\n    prob_sup = get_rel_align_prob(rel_align_dict_r, rel_counterpart, rel) / epsilon\n    if prob_sub < theta and prob_sup < theta:\n        if init:\n            prob_sub, prob_sup = theta, theta\n        else:\n            return\n    func_l, func_r = kg_l_func.get(rel, 0.0) / epsilon, kg_r_func.get(rel_counterpart, 0.0) / epsilon\n    factor = 1.0\n    factor_l = 1.0 - head_eqv_prob * prob_sup * func_r\n    factor_r = 1.0 - head_eqv_prob * prob_sub * func_l\n    if prob_sub >= 0.0 and func_l >= 0.0:\n        factor *= factor_l\n    if prob_sup >= 0.0 and func_r >= 0.0:\n        factor *= factor_r\n    if 1.0 - factor > delta:\n        if not ent_align_ongoing_dict.__contains__(tail_counterpart):\n            ent_align_ongoing_dict[tail_counterpart] = 1.0\n        ent_align_ongoing_dict[tail_counterpart] *= factor\n\n\ndef one_iteration_one_way(queue, kg_r_fact_dict_by_head,\n                          kg_l_fact_dict_by_tail,\n                          kg_l_func, kg_r_func,\n                          sub_ent_match, sub_ent_prob,\n                          is_literal_list_r,\n                          rel_align_dict_l, rel_align_dict_r,\n                          rel_ongoing_dict_queue, rel_norm_dict_queue,\n                          ent_match_tuple_queue,\n                          kg_l_ent_embeds, kg_r_ent_embeds,\n                          fusion_func,\n                          theta, epsilon, delta, init=False, ent_align=True):\n    rel_ongoing_dict, rel_norm_dict = dict(), dict()\n    while not queue.empty():\n        # noinspection PyBroadException\n        try:\n            ent_id = queue.get_nowait()\n        except Exception:\n            break\n        ent_align_ongoing_dict = dict()\n        ent_fact_list = kg_l_fact_dict_by_tail.get(ent_id, list())\n        for (rel_id, head_id) in ent_fact_list:\n            head_counterpart, head_eqv_prob = get_counterpart_id_and_prob(sub_ent_match, sub_ent_prob, head_id)\n            if head_counterpart is None or head_eqv_prob < theta:\n                continue\n            ent_counterpart, tail_eqv_prob = get_counterpart_id_and_prob(sub_ent_match, sub_ent_prob, ent_id)\n            if ent_counterpart is not None:\n                register_rel_align_prob_norm(rel_norm_dict, rel_id, head_eqv_prob * tail_eqv_prob)\n            head_counterpart_fact_list = kg_r_fact_dict_by_head.get(head_counterpart, list())\n            for (rel_counterpart_id, tail_counterpart_id) in head_counterpart_fact_list:\n                if is_literal_list_r[tail_counterpart_id]:\n                    continue\n                eqv_prob = tail_eqv_prob if tail_counterpart_id == ent_counterpart else 0.0\n                if eqv_prob > 0.0:\n                    register_ongoing_prob_product(rel_ongoing_dict, rel_id, rel_counterpart_id,\n                                                  head_eqv_prob * eqv_prob)\n                if ent_align:\n                    register_ent_equality(ent_align_ongoing_dict, rel_align_dict_l, rel_align_dict_r,\n                                          kg_l_func, kg_r_func,\n                                          rel_id, rel_counterpart_id, tail_counterpart_id,\n                                          head_eqv_prob, theta, epsilon, delta, init)\n        if ent_align:\n            update_ent_align_prob(ent_align_ongoing_dict, sub_ent_match, sub_ent_prob, kg_l_ent_embeds, kg_r_ent_embeds, ent_id, fusion_func, init)\n    rel_ongoing_dict_queue.put(rel_ongoing_dict), rel_norm_dict_queue.put(rel_norm_dict)\n    ent_match_tuple_queue.put((sub_ent_match, sub_ent_prob))\n    exit(1)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:51:40.826553Z","iopub.execute_input":"2022-12-25T09:51:40.827611Z","iopub.status.idle":"2022-12-25T09:51:40.851108Z","shell.execute_reply.started":"2022-12-25T09:51:40.827570Z","shell.execute_reply":"2022-12-25T09:51:40.850025Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import gc\nimport sys\nimport random\nimport multiprocessing as mp","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:51:56.426217Z","iopub.execute_input":"2022-12-25T09:51:56.426586Z","iopub.status.idle":"2022-12-25T09:51:56.432219Z","shell.execute_reply.started":"2022-12-25T09:51:56.426556Z","shell.execute_reply":"2022-12-25T09:51:56.431159Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"sys.setrecursionlimit(1000000)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:52:15.700702Z","iopub.execute_input":"2022-12-25T09:52:15.701137Z","iopub.status.idle":"2022-12-25T09:52:15.706940Z","shell.execute_reply.started":"2022-12-25T09:52:15.701100Z","shell.execute_reply":"2022-12-25T09:52:15.705651Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class KGs:\n    def __init__(self, kg1: KG, kg2: KG, theta=0.1, iteration=3, workers=4, fusion_func=None):\n        self.kg_l = kg1\n        self.kg_r = kg2\n        self.theta = theta\n        self.iteration = iteration\n        self.delta = 0.01\n        self.epsilon = 1.01\n        self.const = 10.0\n        self.workers = workers\n        self.fusion_func = fusion_func\n\n        self.rel_ongoing_dict_l, self.rel_ongoing_dict_r = dict(), dict()\n        self.rel_norm_dict_l, self.rel_norm_dict_r = dict(), dict()\n        self.rel_align_dict_l, self.rel_align_dict_r = dict(), dict()\n\n        self.sub_ent_match = None\n        self.sup_ent_match = None\n        self.sub_ent_prob = None\n        self.sup_ent_prob = None\n\n        self._iter_num = 0\n        self.has_load = False\n        self.util = KGsUtil(self, self.__get_counterpart_and_prob, self.__set_counterpart_and_prob)\n        self.__init()\n\n    def __init(self):\n        if not self.kg_l.is_init():\n            self.kg_l.init()\n        if not self.kg_r.is_init():\n            self.kg_r.init()\n\n        kg_l_ent_num = len(self.kg_l.entity_set) + len(self.kg_l.literal_set)\n        kg_r_ent_num = len(self.kg_r.entity_set) + len(self.kg_r.literal_set)\n        self.sub_ent_match = [None for _ in range(kg_l_ent_num)]\n        self.sub_ent_prob = [0.0 for _ in range(kg_l_ent_num)]\n        self.sup_ent_match = [None for _ in range(kg_r_ent_num)]\n        self.sup_ent_prob = [0.0 for _ in range(kg_r_ent_num)]\n\n        for lite_l in self.kg_l.literal_set:\n            if self.kg_r.literal_dict_by_value.__contains__(lite_l.value):\n                lite_r = self.kg_r.literal_dict_by_value[lite_l.value]\n                l_id, r_id = lite_l.id, lite_r.id\n                self.sub_ent_match[l_id], self.sup_ent_match[r_id] = lite_r.id, lite_l.id\n                self.sub_ent_prob[l_id], self.sup_ent_prob[r_id] = 1.0, 1.0\n\n    def __get_counterpart_and_prob(self, ent):\n        source = ent.affiliation is self.kg_l\n        counterpart_id = self.sub_ent_match[ent.id] if source else self.sup_ent_match[ent.id]\n        if counterpart_id is None:\n            return None, 0.0\n        else:\n            counterpart = self.kg_r.ent_lite_list_by_id[counterpart_id] if source \\\n                else self.kg_l.ent_lite_list_by_id[counterpart_id]\n            return counterpart, self.sub_ent_prob[ent.id] if source else self.sup_ent_prob[ent.id]\n\n    def __set_counterpart_and_prob(self, ent_l, ent_r, prob, force=False):\n        source = ent_l.affiliation is self.kg_l\n        l_id, r_id = ent_l.id, ent_r.id\n        curr_prob = self.sub_ent_prob[l_id] if source else self.sup_ent_prob[l_id]\n        if not force and prob < curr_prob:\n            return False\n        if source:\n            self.sub_ent_match[l_id], self.sub_ent_prob[l_id] = r_id, prob\n        else:\n            self.sup_ent_match[l_id], self.sup_ent_prob[l_id] = r_id, prob\n        return True\n\n    def set_fusion_func(self, func):\n        self.fusion_func = func\n\n    def set_iteration(self, iteration):\n        self.iteration = iteration\n\n    def set_worker_num(self, worker_num):\n        self.workers = worker_num\n\n    def run(self, test_path=None):\n        start_time = time.time()\n        print(\"Start...\")\n        for i in range(self.iteration):\n            self._iter_num = i\n            print(str(i + 1) + \"-th iteration......\")\n            self.__run_per_iteration()\n            self.util.test(path=test_path, threshold=[0.1 * i for i in range(10)])\n            gc.collect()\n        print(\"PARIS Completed!\")\n        end_time = time.time()\n        print(\"Total time: \" + str(end_time - start_time))\n\n    def __run_per_iteration(self):\n        self.__run_per_iteration_one_way(self.kg_l)\n        self.__ent_bipartite_matching()\n        self.__run_per_iteration_one_way(self.kg_r, ent_align=False)\n        return\n\n    def __run_per_iteration_one_way(self, kg: KG, ent_align=True):\n        kg_other = self.kg_l if kg is self.kg_r else self.kg_r\n        ent_list = self.__generate_list(kg)\n        mgr = mp.Manager()\n        ent_queue = mgr.Queue(len(ent_list))\n        for ent_id in ent_list:\n            ent_queue.put(ent_id)\n\n        rel_ongoing_dict_queue = mgr.Queue()\n        rel_norm_dict_queue = mgr.Queue()\n        ent_match_tuple_queue = mgr.Queue()\n\n        kg_r_fact_dict_by_head = kg_other.fact_dict_by_head\n        kg_l_fact_dict_by_tail = kg.fact_dict_by_tail\n        kg_l_func, kg_r_func = kg.functionality_dict, kg_other.functionality_dict\n\n        rel_align_dict_l, rel_align_dict_r = self.rel_align_dict_l, self.rel_align_dict_r\n\n        if kg is self.kg_l:\n            ent_match, ent_prob = self.sub_ent_match, self.sub_ent_prob\n            is_literal_list_r = self.kg_r.is_literal_list\n        else:\n            ent_match, ent_prob = self.sup_ent_match, self.sup_ent_prob\n            rel_align_dict_l, rel_align_dict_r = rel_align_dict_r, rel_align_dict_l\n            is_literal_list_r = self.kg_l.is_literal_list\n\n        init = not self.has_load and self._iter_num <= 1\n        tasks = []\n        kg_l_ent_embeds, kg_r_ent_embeds = kg.ent_embeddings, kg_other.ent_embeddings\n        for _ in range(self.workers):\n            task = mp.Process(target=one_iteration_one_way, args=(ent_queue, kg_r_fact_dict_by_head,\n                                                                  kg_l_fact_dict_by_tail,\n                                                                  kg_l_func, kg_r_func,\n                                                                  ent_match, ent_prob,\n                                                                  is_literal_list_r,\n                                                                  rel_align_dict_l, rel_align_dict_r,\n                                                                  rel_ongoing_dict_queue, rel_norm_dict_queue,\n                                                                  ent_match_tuple_queue,\n                                                                  kg_l_ent_embeds, kg_r_ent_embeds,\n                                                                  self.fusion_func,\n                                                                  self.theta, self.epsilon, self.delta, init,\n                                                                  ent_align))\n            task.start()\n            tasks.append(task)\n\n        for task in tasks:\n            task.join()\n\n        self.__clear_ent_match_and_prob(ent_match, ent_prob)\n        while not ent_match_tuple_queue.empty():\n            ent_match_tuple = ent_match_tuple_queue.get()\n            self.__merge_ent_align_result(ent_match, ent_prob, ent_match_tuple[0], ent_match_tuple[1])\n\n        rel_ongoing_dict = self.rel_ongoing_dict_l if kg is self.kg_l else self.rel_ongoing_dict_r\n        rel_norm_dict = self.rel_norm_dict_l if kg is self.kg_l else self.rel_norm_dict_r\n        rel_align_dict = self.rel_align_dict_l if kg is self.kg_l else self.rel_align_dict_r\n\n        rel_ongoing_dict.clear(), rel_norm_dict.clear(), rel_align_dict.clear()\n        while not rel_ongoing_dict_queue.empty():\n            self.__merge_rel_ongoing_dict(rel_ongoing_dict, rel_ongoing_dict_queue.get())\n\n        while not rel_norm_dict_queue.empty():\n            self.__merge_rel_norm_dict(rel_norm_dict, rel_norm_dict_queue.get())\n\n        self.__update_rel_align_dict(rel_align_dict, rel_ongoing_dict, rel_norm_dict)\n\n    @staticmethod\n    def update_ent_embeds(kg, new_ent_emb_dict, alpha=0.5):\n        def update_function(emb_origin, emb_new):\n            emb_pool = alpha * emb_origin + (1.0 - alpha) * emb_new\n            return emb_pool / np.linalg.norm(emb_pool)\n\n        for (idx, emb) in new_ent_emb_dict.items():\n            kg.set_ent_embedding(idx, emb, update_function)\n\n    @staticmethod\n    def __generate_list(kg: KG):\n        ent_list = kg.ent_id_list\n        random.shuffle(ent_list)\n        return ent_list\n\n    @staticmethod\n    def __merge_rel_ongoing_dict(rel_dict_l, rel_dict_r):\n        for (rel, rel_counterpart_dict) in rel_dict_r.items():\n            if not rel_dict_l.__contains__(rel):\n                rel_dict_l[rel] = rel_counterpart_dict\n            else:\n                for (rel_counterpart, prob) in rel_counterpart_dict.items():\n                    if not rel_dict_l[rel].__contains__(rel_counterpart):\n                        rel_dict_l[rel][rel_counterpart] = prob\n                    else:\n                        rel_dict_l[rel][rel_counterpart] += prob\n\n    @staticmethod\n    def __merge_rel_norm_dict(norm_dict_l, norm_dict_r):\n        for (rel, norm) in norm_dict_r.items():\n            if not norm_dict_l.__contains__(rel):\n                norm_dict_l[rel] = norm\n            else:\n                norm_dict_l[rel] += norm\n\n    @staticmethod\n    def __update_rel_align_dict(rel_align_dict, rel_ongoing_dict, rel_norm_dict, const=10.0):\n        for (rel, counterpart_dict) in rel_ongoing_dict.items():\n            norm = rel_norm_dict.get(rel, 1.0)\n            if not rel_align_dict.__contains__(rel):\n                rel_align_dict[rel] = dict()\n            rel_align_dict[rel].clear()\n            for (counterpart, score) in counterpart_dict.items():\n                prob = score / (const + norm)\n                rel_align_dict[rel][counterpart] = prob\n\n    def __ent_bipartite_matching(self):\n        for ent_l in self.kg_l.entity_set:\n            ent_id = ent_l.id\n            counterpart_id, prob = self.sub_ent_match[ent_id], self.sub_ent_prob[ent_id]\n            if counterpart_id is None:\n                continue\n            counterpart_prob = self.sup_ent_prob[counterpart_id]\n            if counterpart_prob < prob:\n                self.sup_ent_match[counterpart_id] = ent_id\n                self.sup_ent_prob[counterpart_id] = prob\n        for ent_l in self.kg_l.entity_set:\n            ent_id = ent_l.id\n            sub_counterpart_id = self.sub_ent_match[ent_id]\n            if sub_counterpart_id is None:\n                continue\n            sup_counterpart_id = self.sup_ent_match[sub_counterpart_id]\n            if sup_counterpart_id is None:\n                continue\n            if sup_counterpart_id != ent_id:\n                self.sub_ent_match[ent_id], self.sub_ent_prob[ent_id] = None, 0.0\n\n    @staticmethod\n    def __merge_ent_align_result(ent_match_l, ent_prob_l, ent_match_r, ent_prob_r):\n        assert len(ent_match_l) == len(ent_match_r)\n        for i in range(len(ent_prob_l)):\n            if ent_prob_l[i] < ent_prob_r[i]:\n                ent_prob_l[i] = ent_prob_r[i]\n                ent_match_l[i] = ent_match_r[i]\n\n    @staticmethod\n    def __clear_ent_match_and_prob(ent_match, ent_prob):\n        for i in range(len(ent_match)):\n            ent_match[i] = None\n            ent_prob[i] = 0.0","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:52:53.096943Z","iopub.execute_input":"2022-12-25T09:52:53.097397Z","iopub.status.idle":"2022-12-25T09:52:53.147233Z","shell.execute_reply.started":"2022-12-25T09:52:53.097359Z","shell.execute_reply":"2022-12-25T09:52:53.146035Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class KGsUtil:\n    def __init__(self, kgs, get_counterpart_and_prob, set_counterpart_and_prob):\n        self.kgs = kgs\n        self.__get_counterpart_and_prob = get_counterpart_and_prob\n        self.__set_counterpart_and_prob = set_counterpart_and_prob\n        self.ent_links_candidate = list()\n\n    def reset_ent_align_result(self):\n        for ent in self.kgs.kg_l.entity_set:\n            idx = ent.id\n            self.kgs.sub_ent_match[idx], self.kgs.sub_ent_prob[idx] = None, 0.0\n        for ent in self.kgs.kg_r.entity_set:\n            idx = ent.id\n            self.kgs.sup_ent_match[idx], self.kgs.sup_ent_prob[idx] = None, 0.0\n        emb_l, emb_r = self.kgs.kg_l.ent_embeddings, self.kgs.kg_r.ent_embeddings\n        matrix = np.matmul(emb_l, emb_r.T)\n        max_indices = np.argmax(matrix, axis=1)\n        print(max_indices)\n        for i in range(len(max_indices)):\n            counterpart_id = max_indices[i]\n            self.kgs.sub_ent_match[i], self.kgs.sub_ent_prob[i] = counterpart_id, 0.2\n            self.kgs.sup_ent_match[counterpart_id], self.kgs.sup_ent_prob[counterpart_id] = i, 0.2\n\n    def test(self, path, threshold):\n        gold_result = set()\n        with open(path, \"r\", encoding=\"utf8\") as f:\n            for line in f.readlines():\n                params = str.strip(line).split(\"\\t\")\n                ent_l, ent_r = params[0].strip(), params[1].strip()\n                obj_l, obj_r = self.kgs.kg_l.entity_dict_by_name.get(ent_l), self.kgs.kg_r.entity_dict_by_name.get(\n                    ent_r)\n                if obj_l is None:\n                    print(\"Exception: fail to load Entity (\" + ent_l + \")\")\n                if obj_r is None:\n                    print(\"Exception: fail to load Entity (\" + ent_r + \")\")\n                if obj_l is None or obj_r is None:\n                    continue\n                gold_result.add((obj_l.id, obj_r.id))\n\n        threshold_list = []\n        if isinstance(threshold, float) or isinstance(threshold, int):\n            threshold_list.append(float(threshold))\n        else:\n            threshold_list = threshold\n\n        for threshold_item in threshold_list:\n            ent_align_result = set()\n            for ent_id in self.kgs.kg_l.ent_id_list:\n                counterpart_id = self.kgs.sub_ent_match[ent_id]\n                if counterpart_id is not None:\n                    prob = self.kgs.sub_ent_prob[ent_id]\n                    if prob < threshold_item:\n                        continue\n                    ent_align_result.add((ent_id, counterpart_id))\n\n            correct_num = len(gold_result & ent_align_result)\n            predict_num = len(ent_align_result)\n            total_num = len(gold_result)\n\n            if predict_num == 0:\n                print(\"Threshold: \" + format(threshold_item, \".3f\") + \"\\tException: no satisfied alignment result\")\n                continue\n\n            if total_num == 0:\n                print(\"Threshold: \" + format(threshold_item, \".3f\") + \"\\tException: no satisfied instance for testing\")\n            else:\n                precision, recall = correct_num / predict_num, correct_num / total_num\n                if precision <= 0.0 or recall <= 0.0:\n                    print(\"Threshold: \" + format(threshold_item, \".3f\") + \"\\tPrecision: \" + format(precision, \".6f\") +\n                          \"\\tRecall: \" + format(recall, \".6f\") + \"\\tF1-Score: Nan\")\n                else:\n                    f1_score = 2.0 * precision * recall / (precision + recall)\n                    print(\"Threshold: \" + format(threshold_item, \".3f\") + \"\\tPrecision: \" + format(precision, \".6f\") +\n                          \"\\tRecall: \" + format(recall, \".6f\") + \"\\tF1-Score: \" + format(f1_score, \".6f\"))\n\n    def generate_input_for_embed_align(self, link_path, save_dir=\"output\", threshold=0.0):\n        ent_align_predict, visited = set(), set()\n        for ent in self.kgs.kg_l.entity_set:\n            counterpart, prob = self.__get_counterpart_and_prob(ent)\n            if prob < threshold or counterpart is None:\n                continue\n            ent_align_predict.add((ent, counterpart))\n            visited.add(ent)\n\n        ent_align_test = set()\n        with open(link_path, \"r\", encoding=\"utf8\") as f:\n            for line in f.readlines():\n                params = str.strip(line).split(\"\\t\")\n                ent_l, ent_r = params[0].strip(), params[1].strip()\n                obj_l, obj_r = self.kgs.kg_l.entity_dict_by_name.get(ent_l), self.kgs.kg_r.entity_dict_by_name.get(\n                    ent_r)\n                if obj_l is None or obj_r is None:\n                    continue\n                if obj_l not in visited:\n                    ent_align_test.add((obj_l, obj_r))\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        train_path = os.path.join(save_dir, \"train_links\")\n        test_path = os.path.join(save_dir, \"test_links\")\n        valid_path = os.path.join(save_dir, \"valid_links\")\n\n        def writer(path, result_set):\n            with open(path, \"w\", encoding=\"utf8\") as file:\n                num, length = 0, len(result_set)\n                for (l, r) in result_set:\n                    file.write(\"\\t\".join([l.name, r.name]))\n                    num += 1\n                    if num < length:\n                        file.write(\"\\n\")\n\n        writer(train_path, ent_align_predict)\n        writer(test_path, ent_align_test)\n        writer(valid_path, ent_align_test)\n        print(\"training size: \" + str(len(ent_align_predict)) + \"\\ttest size: \" + str(len(ent_align_test)))\n\n    def save_results(self, path=\"output/EA_Result.txt\"):\n        ent_dict, lite_dict, attr_dict, rel_dict = dict(), dict(), dict(), dict()\n        for obj in (self.kgs.kg_l.entity_set | self.kgs.kg_l.literal_set):\n            counterpart, prob = self.__get_counterpart_and_prob(obj)\n            if counterpart is not None:\n                if obj.is_literal():\n                    lite_dict[(obj, counterpart)] = [prob]\n                else:\n                    ent_dict[(obj, counterpart)] = [prob]\n\n        for (rel_id, rel_counterpart_id_dict) in self.kgs.rel_align_dict_l.items():\n            rel = self.kgs.kg_l.rel_attr_list_by_id[rel_id]\n            dictionary = attr_dict if rel.is_attribute() else rel_dict\n            for (rel_counterpart_id, prob) in rel_counterpart_id_dict.items():\n                if prob > self.kgs.theta:\n                    rel_counterpart = self.kgs.kg_r.rel_attr_list_by_id[rel_counterpart_id]\n                    dictionary[(rel, rel_counterpart)] = [prob, 0.0]\n\n        for (rel_id, rel_counterpart_id_dict) in self.kgs.rel_align_dict_r.items():\n            rel = self.kgs.kg_r.rel_attr_list_by_id[rel_id]\n            dictionary = attr_dict if rel.is_attribute() else rel_dict\n            for (rel_counterpart_id, prob) in rel_counterpart_id_dict.items():\n                if prob > self.kgs.theta:\n                    rel_counterpart = self.kgs.kg_l.rel_attr_list_by_id[rel_counterpart_id]\n                    if not dictionary.__contains__((rel_counterpart, rel)):\n                        dictionary[(rel_counterpart, rel)] = [0.0, 0.0]\n                    dictionary[(rel_counterpart, rel)][-1] = prob\n        base, _ = os.path.split(path)\n        if not os.path.exists(base):\n            os.makedirs(base)\n        if os.path.exists(path):\n            os.remove(path)\n        self.__result_writer(path, attr_dict, \"Attribute Alignment\")\n        self.__result_writer(path, rel_dict, \"Relation Alignment\")\n        self.__result_writer(path, lite_dict, \"Literal Alignment\")\n        self.__result_writer(path, ent_dict, \"Entity Alignment\")\n        return\n\n    def save_params(self, path=\"output/EA_Params\"):\n        base, _ = os.path.split(path)\n        if not os.path.exists(base):\n            os.makedirs(base)\n        with open(path, \"w\", encoding=\"utf8\") as f:\n            for obj in (self.kgs.kg_l.entity_set | self.kgs.kg_l.literal_set):\n                counterpart, prob = self.__get_counterpart_and_prob(obj)\n                if counterpart is not None:\n                    f.write(\"\\t\".join([\"L\", obj.name, counterpart.name, str(prob)]) + \"\\n\")\n            for obj in (self.kgs.kg_r.entity_set | self.kgs.kg_r.literal_set):\n                counterpart, prob = self.__get_counterpart_and_prob(obj)\n                if counterpart is not None:\n                    f.write(\"\\t\".join([\"R\", obj.name, counterpart.name, str(prob)]) + \"\\n\")\n            for (rel_id, rel_counterpart_id_dict) in self.kgs.rel_align_dict_l.items():\n                rel = self.kgs.kg_l.rel_attr_list_by_id[rel_id]\n                for (rel_counterpart_id, prob) in rel_counterpart_id_dict.items():\n                    if prob > 0.0:\n                        rel_counterpart = self.kgs.kg_r.rel_attr_list_by_id[rel_counterpart_id]\n                        prefix = \"L\"\n                        f.write(\"\\t\".join([prefix, rel.name, rel_counterpart.name, str(prob)]) + \"\\n\")\n            for (rel_id, rel_counterpart_id_dict) in self.kgs.rel_align_dict_r.items():\n                rel = self.kgs.kg_r.rel_attr_list_by_id[rel_id]\n                for (rel_counterpart_id, prob) in rel_counterpart_id_dict.items():\n                    if prob > 0.0:\n                        rel_counterpart = self.kgs.kg_l.rel_attr_list_by_id[rel_counterpart_id]\n                        prefix = \"R\"\n                        f.write(\"\\t\".join([prefix, rel.name, rel_counterpart.name, str(prob)]) + \"\\n\")\n        return\n\n    def load_params(self, path=\"output/EA_Params\", init=True):\n        self.kgs.has_load = init\n\n        def get_obj_by_name(kg_l, kg_r, name1, name2):\n            obj1, obj2 = kg_l.literal_dict_by_name.get(name1), kg_r.literal_dict_by_name.get(name2)\n            if obj1 is None or obj2 is None:\n                obj1, obj2 = kg_l.entity_dict_by_name.get(name1), kg_r.entity_dict_by_name.get(name2)\n            if obj1 is None or obj2 is None:\n                obj1, obj2 = kg_l.entity_dict_by_name.get(name1), kg_r.entity_dict_by_name.get(name2)\n            if obj1 is None or obj2 is None:\n                obj1, obj2 = kg_l.relation_dict_by_name.get(name1), kg_r.relation_dict_by_name.get(name2)\n            if obj1 is None or obj2 is None:\n                obj1, obj2 = kg_l.attribute_dict_by_name.get(name1), kg_r.attribute_dict_by_name.get(name2)\n            return obj1, obj2\n\n        with open(path, \"r\", encoding=\"utf8\") as f:\n            for line in f.readlines():\n                if len(line.strip()) == 0:\n                    continue\n                params = line.strip().split(\"\\t\")\n                assert len(params) == 4\n                prefix, name_l, name_r, prob = params[0].strip(), params[1].strip(), params[2].strip(), float(\n                    params[3].strip())\n                if prefix == \"L\":\n                    obj_l, obj_r = get_obj_by_name(self.kgs.kg_l, self.kgs.kg_r, name_l, name_r)\n                else:\n                    obj_l, obj_r = get_obj_by_name(self.kgs.kg_r, self.kgs.kg_l, name_l, name_r)\n                assert (obj_l is not None and obj_r is not None)\n                if obj_l.is_entity():\n                    idx_l = obj_l.id\n                    if prefix == \"L\":\n                        self.kgs.sub_ent_match[idx_l], self.kgs.sub_ent_prob[idx_l] = obj_r.id, prob\n                    else:\n                        self.kgs.sup_ent_match[idx_l], self.kgs.sup_ent_prob[idx_l] = obj_r.id, prob\n                else:\n                    if prefix == \"L\":\n                        self.__params_loader_helper(self.kgs.rel_align_dict_l, obj_l.id, obj_r.id, prob)\n                    else:\n                        self.__params_loader_helper(self.kgs.rel_align_dict_r, obj_l.id, obj_r.id, prob)\n        return\n\n    def load_ent_links(self, path, func=None, num=None, init_value=None, threshold_min=0.0, threshold_max=1.0,\n                       force=False):\n        ent_link_list = list()\n        with open(path, \"r\", encoding=\"utf8\") as f:\n            for line in f.readlines():\n                line = line.strip()\n                if len(line) == 0:\n                    continue\n                params = line.split(sep=\"\\t\")\n                name_l, name_r = params[0].strip(), params[1].strip()\n                obj_l, obj_r = self.kgs.kg_l.get_object_by_name(name_l), self.kgs.kg_r.get_object_by_name(name_r)\n                if obj_l is None or obj_r is None:\n                    continue\n                if init_value is None:\n                    if len(params) == 3:\n                        prob = float(params[2].strip())\n                    else:\n                        prob = 1.0\n                else:\n                    prob = init_value\n                if prob < threshold_min or prob > threshold_max:\n                    continue\n                if func is not None:\n                    prob = func(prob)\n                ent_link_list.append((obj_l, obj_r, prob))\n        random_list = random.choices(ent_link_list, k=num) if num is not None else ent_link_list\n        change_num = 0\n        for (obj_l, obj_r, prob) in random_list:\n            success = self.__set_counterpart_and_prob(obj_l, obj_r, prob, force)\n            success &= self.__set_counterpart_and_prob(obj_r, obj_l, prob, force)\n            change_num += 1 if success else 0\n        print(\"load num: \" + str(len(random_list)) + \"\\t change num: \" + str(change_num))\n\n    def reset_ent_align_prob(self, func):\n        for ent in self.kgs.kg_l.entity_set:\n            idx = ent.id\n            self.kgs.sub_ent_prob[idx] = func(self.kgs.sub_ent_prob[idx])\n        for ent in self.kgs.kg_r.entity_set:\n            idx = ent.id\n            self.kgs.sup_ent_prob[idx] = func(self.kgs.sup_ent_prob[idx])\n\n    def load_embedding(self, ent_emb_path, kg_l_mapping, kg_r_mapping):\n        ent_emb = np.load(ent_emb_path)\n\n        def load_emb_helper(kg, mapping_path):\n            with open(mapping_path, \"r\", encoding=\"utf8\") as f:\n                for line in f.readlines():\n                    if len(line.strip()) == 0:\n                        continue\n                    params = line.strip().split(\"\\t\")\n                    ent_name, idx = params[0].strip(), int(params[1].strip())\n                    ent = kg.entity_dict_by_name.get(ent_name)\n                    if ent is not None:\n                        ent.embedding = ent_emb[idx, :]\n\n        load_emb_helper(self.kgs.kg_l, kg_l_mapping)\n        load_emb_helper(self.kgs.kg_r, kg_r_mapping)\n        self.kgs.kg_l.init_ent_embeddings()\n        self.kgs.kg_r.init_ent_embeddings()\n\n    @staticmethod\n    def __result_writer(path, result_dict, title):\n        with open(path, \"a+\", encoding=\"utf-8\") as f:\n            f.write(\"--- \" + title + \" ---\\n\\n\")\n            for ((obj_l, obj_r), prob_set) in result_dict.items():\n                f.write(obj_l.name + \"\\t\" + obj_r.name + \"\\t\" + \"\\t\".join(format(s, \".6f\") for s in prob_set) + \"\\n\")\n            f.write(\"\\n\")\n\n    @staticmethod\n    def __params_loader_helper(dict_by_key: dict, key1, key2, value):\n        if not dict_by_key.__contains__(key1):\n            dict_by_key[key1] = dict()\n        dict_by_key[key1][key2] = value","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:53:32.579729Z","iopub.execute_input":"2022-12-25T09:53:32.580136Z","iopub.status.idle":"2022-12-25T09:53:32.649471Z","shell.execute_reply.started":"2022-12-25T09:53:32.580105Z","shell.execute_reply":"2022-12-25T09:53:32.648401Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def construct_kg(path_r, path_a=None, sep='\\t', name=None):\n    kg = KG(name=name)\n    if path_a is not None:\n        with open(path_r, \"r\", encoding=\"utf-8\") as f:\n            for line in f.readlines():\n                if len(line.strip()) == 0:\n                    continue\n                params = str.strip(line).split(sep=sep)\n                if len(params) != 3:\n                    print(line)\n                    continue\n                h, r, t = params[0].strip(), params[1].strip(), params[2].strip()\n                kg.insert_relation_tuple(h, r, t)\n\n        with open(path_a, \"r\", encoding=\"utf-8\") as f:\n            for line in f.readlines():\n                if len(line.strip()) == 0:\n                    continue\n                params = str.strip(line).split(sep=sep)\n                if len(params) != 3:\n                    print(line)\n                    continue\n                # assert len(params) == 3\n                e, a, v = params[0].strip(), params[1].strip(), params[2].strip()\n                kg.insert_attribute_tuple(e, a, v)\n    else:\n        with open(path_r, \"r\", encoding=\"utf-8\") as f:\n            prev_line = \"\"\n            for line in f.readlines():\n                params = line.strip().split(sep)\n                if len(params) != 3 or len(prev_line) == 0:\n                    prev_line += \"\\n\" if len(line.strip()) == 0 else line.strip()\n                    continue\n                prev_params = prev_line.strip().split(sep)\n                e, a, v = prev_params[0].strip(), prev_params[1].strip(), prev_params[2].strip()\n                prev_line = \"\".join(line)\n                if len(e) == 0 or len(a) == 0 or len(v) == 0:\n                    print(\"Exception: \" + e)\n                    continue\n                if v.__contains__(\"http\"):\n                    kg.insert_relation_tuple(e, a, v)\n                else:\n                    kg.insert_attribute_tuple(e, a, v)\n    kg.init()\n    kg.print_kg_info()\n    return kg","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:54:07.073774Z","iopub.execute_input":"2022-12-25T09:54:07.074870Z","iopub.status.idle":"2022-12-25T09:54:07.089804Z","shell.execute_reply.started":"2022-12-25T09:54:07.074821Z","shell.execute_reply":"2022-12-25T09:54:07.088847Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def construct_kgs(dataset_dir, name=\"KGs\", load_chk=None):\n    path_r_1 = os.path.join(dataset_dir, \"rel_triples_1\")\n    path_a_1 = os.path.join(dataset_dir, \"attr_triples_1\")\n\n    path_r_2 = os.path.join(dataset_dir, \"rel_triples_2\")\n    path_a_2 = os.path.join(dataset_dir, \"attr_triples_2\")\n\n    kg1 = construct_kg(path_r_1, path_a_1, name=str(name + \"-KG1\"))\n    kg2 = construct_kg(path_r_2, path_a_2, name=str(name + \"-KG2\"))\n    kgs = KGs(kg1=kg1, kg2=kg2)\n    # load the previously saved PRASE model\n    if load_chk is not None:\n        kgs.util.load_params(load_chk)\n    return kgs","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:54:11.844319Z","iopub.execute_input":"2022-12-25T09:54:11.844680Z","iopub.status.idle":"2022-12-25T09:54:11.852007Z","shell.execute_reply.started":"2022-12-25T09:54:11.844651Z","shell.execute_reply":"2022-12-25T09:54:11.850954Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# the balancing function for PRASE\ndef fusion_func(prob, x, y):\n    return 0.8 * prob + 0.2 * np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n\n\ndef run_init_iteration(kgs, ground_truth_path=None):\n    kgs.run(test_path=ground_truth_path)\n\n\ndef run_prase_iteration(kgs, embed_dir, ground_truth_path=None, load_weight=1.0, reset_weight=1.0, load_ent=True,\n                        load_emb=True,\n                        init_reset=False, prase_func=None):\n    if init_reset is True:\n        # load_weight: scale the mapping probability predicted by the PARIS module if loading PRASE from check point\n        kgs.util.reset_ent_align_prob(lambda x: reset_weight * x)\n\n    # mapping feedback\n    if load_ent is True:\n        ent_links_path = os.path.join(embed_dir, \"alignment_results_12\")\n        # load_weight: scale the mapping probability predicted by the embedding module\n        kgs.util.load_ent_links(func=lambda x: load_weight * x, path=ent_links_path, force=True)\n\n    # embedding feedback\n    if load_emb is True:\n        mapping_l, mapping_r = os.path.join(embed_dir, \"kg1_ent_ids\"), os.path.join(embed_dir, \"kg2_ent_ids\")\n        ent_emb_path = os.path.join(embed_dir, \"ent_embeds.npy\")\n        kgs.util.load_embedding(ent_emb_path, mapping_l, mapping_r)\n\n    # set the function balancing the probability (from PARIS) and the embedding similarity\n    kgs.set_fusion_func(prase_func)\n    kgs.run(test_path=ground_truth_path)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T09:54:20.562122Z","iopub.execute_input":"2022-12-25T09:54:20.563085Z","iopub.status.idle":"2022-12-25T09:54:20.572372Z","shell.execute_reply.started":"2022-12-25T09:54:20.563030Z","shell.execute_reply":"2022-12-25T09:54:20.571270Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"__file__ = '/kaggle/input/d-w-15k'   # Changed here","metadata":{"execution":{"iopub.status.busy":"2022-12-25T10:05:26.520988Z","iopub.execute_input":"2022-12-25T10:05:26.521435Z","iopub.status.idle":"2022-12-25T10:05:26.525887Z","shell.execute_reply.started":"2022-12-25T10:05:26.521400Z","shell.execute_reply":"2022-12-25T10:05:26.525081Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    base, _ = os.path.split(os.path.abspath(__file__))\n    dataset_name = \"d-w-15k\"              # Changed here\n    # embed_module_name = \"MultiKE\"\n    embed_module_name = \"BootEA\"\n\n    dataset_path = os.path.join(os.path.join(base), dataset_name)   # changed here\n    embed_output_path = os.path.join(dataset_path, embed_module_name)\n\n    print(\"Construct KGs...\")\n    # load the KG files from relation and attribute triples to construct the KGs object\n    # use load_chk to load the PARIS model from a check point\n    # note that, due to the limitation of file size, we do not provide the check point file for performing PRASE\n    # surprisingly, it may make the result better than the one reported in the paper\n    kgs = construct_kgs(dataset_dir=dataset_path, name=dataset_name, load_chk=None)\n\n    # set the number of processes\n    kgs.set_worker_num(6)\n\n    # set the iteration number of PARIS\n    kgs.set_iteration(10)\n\n    # ground truth mapping path\n    ground_truth_mapping_path = os.path.join(dataset_path, \"ent_links\")\n\n    # test the model and show the metrics\n    # kgs.util.test(path=ground_truth_mapping_path, threshold=0.1)\n\n    # using the following line of code to run the initial iteration of PRASE (i.e., PARIS, without any feedback)\n    # the ground truth path is used to show the metrics during the iterations of PARIS\n    # run_init_iteration(kgs=kgs, ground_truth_path=ground_truth_mapping_path)\n\n    # run PRASE using both the embedding and mapping feedback\n    run_prase_iteration(kgs, embed_dir=embed_output_path, prase_func=fusion_func,\n                        ground_truth_path=ground_truth_mapping_path)\n\n    # in the following, we store the mappings and check point files\n    save_dir_name = \"output\" \n    base1 = \"/kaggle/working/\"           # Changed here\n    save_dir_path = os.path.join(os.path.join(base1, save_dir_name), dataset_name)\n    if not os.path.exists(save_dir_path):\n        os.makedirs(save_dir_path)\n\n    time_stamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n\n    # save the check point\n    check_point_dir = os.path.join(save_dir_path, \"chk\")\n    check_point_name = \"PRASE-\" + embed_module_name + \"@\" + time_stamp\n    check_point_file = os.path.join(check_point_dir, check_point_name)\n    kgs.util.save_params(check_point_file)\n\n    # save the mapping result\n    result_dir = os.path.join(save_dir_path, \"mapping\")\n    result_file_name = \"PRASE-\" + embed_module_name + \"@\" + time_stamp + \".txt\"\n    result_file = os.path.join(result_dir, result_file_name)\n    kgs.util.save_results(result_file)\n\n    # generate the input files (training data) for embedding module\n    input_base = os.path.join(save_dir_path, \"embed_input\")\n    input_dir_name = \"PRASE-\" + embed_module_name + \"@\" + time_stamp\n    input_dir = os.path.join(input_base, input_dir_name)\n    kgs.util.generate_input_for_embed_align(link_path=ground_truth_mapping_path, save_dir=input_dir, threshold=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T10:14:03.303807Z","iopub.execute_input":"2022-12-25T10:14:03.304203Z","iopub.status.idle":"2022-12-25T10:19:30.355186Z","shell.execute_reply.started":"2022-12-25T10:14:03.304170Z","shell.execute_reply":"2022-12-25T10:19:30.353564Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Construct KGs...\n\nInformation of Knowledge Graph (d-w-15k-KG1):\n- Relation Tuple Number: 73983\n- Attribute Tuple Number: 66813\n- Entity Number: 15000\n- Relation Number: 167\n- Attribute Number: 175\n- Literal Number: 40614\n- Functionality Statistics:\n--- TOP-10 Relations (Func) ---\nName: http://dbpedia.org/ontology/training\tFunc: 1.0\nName: http://dbpedia.org/ontology/training-(INV)\tFunc: 1.0\nName: http://dbpedia.org/ontology/sourceConfluenceRegion\tFunc: 1.0\nName: http://dbpedia.org/ontology/ethnicity\tFunc: 1.0\nName: http://dbpedia.org/ontology/sourceConfluenceRegion-(INV)\tFunc: 1.0\nName: http://dbpedia.org/ontology/league\tFunc: 1.0\nName: http://dbpedia.org/ontology/photographer\tFunc: 1.0\nName: http://dbpedia.org/ontology/mainInterest\tFunc: 1.0\nName: http://dbpedia.org/ontology/photographer-(INV)\tFunc: 1.0\nName: http://dbpedia.org/ontology/mainInterest-(INV)\tFunc: 1.0\n......\n--- TOP-10 Relations (Func-Inv) ---\nName: http://dbpedia.org/ontology/series-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/training\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/training-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/sourceConfluenceRegion\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/sourceConfluenceRegion-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/photographer\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/headquarter-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/mainInterest\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/photographer-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/mainInterest-(INV)\tFunc-Inv: 1.0\n......\n--- TOP-10 Attributes (Func) ---\nName: http://dbpedia.org/ontology/debut-(INV)\tFunc: 1.0\nName: http://dbpedia.org/ontology/maximumDischarge\tFunc: 1.0\nName: http://dbpedia.org/ontology/watershed\tFunc: 1.0\nName: http://dbpedia.org/ontology/maximumDischarge-(INV)\tFunc: 1.0\nName: http://dbpedia.org/ontology/maximumDepth\tFunc: 1.0\nName: http://dbpedia.org/ontology/salary\tFunc: 1.0\nName: http://dbpedia.org/ontology/watershed-(INV)\tFunc: 1.0\nName: http://dbpedia.org/ontology/salary-(INV)\tFunc: 1.0\nName: http://dbpedia.org/ontology/maximumDepth-(INV)\tFunc: 1.0\nName: http://dbpedia.org/ontology/networth\tFunc: 1.0\n......\n--- TOP-10 Attributes (Func-Inv) ---\nName: http://dbpedia.org/ontology/debut-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/maximumDischarge\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/watershed\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/maximumDischarge-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/maximumDepth\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/salary\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/watershed-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/salary-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/maximumDepth-(INV)\tFunc-Inv: 1.0\nName: http://dbpedia.org/ontology/oclc\tFunc-Inv: 1.0\n......\n\nInformation of Knowledge Graph (d-w-15k-KG2):\n- Relation Tuple Number: 83365\n- Attribute Tuple Number: 175686\n- Entity Number: 15000\n- Relation Number: 121\n- Attribute Number: 457\n- Literal Number: 146977\n- Functionality Statistics:\n--- TOP-10 Relations (Func) ---\nName: http://www.wikidata.org/entity/P451\tFunc: 1.0\nName: http://www.wikidata.org/entity/P945\tFunc: 1.0\nName: http://www.wikidata.org/entity/P421\tFunc: 1.0\nName: http://www.wikidata.org/entity/P406\tFunc: 1.0\nName: http://www.wikidata.org/entity/P945-(INV)\tFunc: 1.0\nName: http://www.wikidata.org/entity/P647\tFunc: 1.0\nName: http://www.wikidata.org/entity/P406-(INV)\tFunc: 1.0\nName: http://www.wikidata.org/entity/P750\tFunc: 1.0\nName: http://www.wikidata.org/entity/P30\tFunc: 1.0\nName: http://www.wikidata.org/entity/P22\tFunc: 1.0\n......\n--- TOP-10 Relations (Func-Inv) ---\nName: http://www.wikidata.org/entity/P740-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P25-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P206-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P945\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P406\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P421-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P945-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P406-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P140-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P22-(INV)\tFunc-Inv: 1.0\n......\n--- TOP-10 Attributes (Func) ---\nName: http://www.wikidata.org/entity/P2970-(INV)\tFunc: 1.0\nName: http://www.wikidata.org/entity/P2769-(INV)\tFunc: 1.0\nName: http://www.wikidata.org/entity/P1239-(INV)\tFunc: 1.0\nName: http://www.wikidata.org/entity/P1617-(INV)\tFunc: 1.0\nName: http://www.wikidata.org/entity/P1707\tFunc: 1.0\nName: http://www.wikidata.org/entity/P409-(INV)\tFunc: 1.0\nName: http://www.wikidata.org/entity/P1296-(INV)\tFunc: 1.0\nName: http://www.wikidata.org/entity/P1711\tFunc: 1.0\nName: http://www.wikidata.org/entity/P699\tFunc: 1.0\nName: http://www.wikidata.org/entity/P1707-(INV)\tFunc: 1.0\n......\n--- TOP-10 Attributes (Func-Inv) ---\nName: http://www.wikidata.org/entity/P2970-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P2769-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P409\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P1239-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P1617-(INV)\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P1296\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P1707\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P1711\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P699\tFunc-Inv: 1.0\nName: http://www.wikidata.org/entity/P1707-(INV)\tFunc-Inv: 1.0\n......\nload num: 1577\t change num: 1577\nStart...\n1-th iteration......\nThreshold: 0.000\tPrecision: 0.937971\tRecall: 0.639133\tF1-Score: 0.760239\nThreshold: 0.100\tPrecision: 0.945129\tRecall: 0.618933\tF1-Score: 0.748016\nThreshold: 0.200\tPrecision: 0.924819\tRecall: 0.348533\tF1-Score: 0.506270\nThreshold: 0.300\tPrecision: 0.916037\tRecall: 0.290933\tF1-Score: 0.441611\nThreshold: 0.400\tPrecision: 0.888576\tRecall: 0.189267\tF1-Score: 0.312064\nThreshold: 0.500\tPrecision: 0.851073\tRecall: 0.129533\tF1-Score: 0.224845\nThreshold: 0.600\tPrecision: 0.825117\tRecall: 0.093733\tF1-Score: 0.168343\nThreshold: 0.700\tPrecision: 0.804469\tRecall: 0.076800\tF1-Score: 0.140214\nThreshold: 0.800\tPrecision: 0.800613\tRecall: 0.069600\tF1-Score: 0.128067\nThreshold: 0.900\tPrecision: 0.783027\tRecall: 0.059667\tF1-Score: 0.110884\n2-th iteration......\nThreshold: 0.000\tPrecision: 0.955739\tRecall: 0.810467\tF1-Score: 0.877128\nThreshold: 0.100\tPrecision: 0.956518\tRecall: 0.808067\tF1-Score: 0.876048\nThreshold: 0.200\tPrecision: 0.958208\tRecall: 0.787200\tF1-Score: 0.864327\nThreshold: 0.300\tPrecision: 0.959970\tRecall: 0.759400\tF1-Score: 0.847986\nThreshold: 0.400\tPrecision: 0.961703\tRecall: 0.734933\tF1-Score: 0.833163\nThreshold: 0.500\tPrecision: 0.964186\tRecall: 0.716133\tF1-Score: 0.821851\nThreshold: 0.600\tPrecision: 0.965375\tRecall: 0.702600\tF1-Score: 0.813289\nThreshold: 0.700\tPrecision: 0.966698\tRecall: 0.687000\tF1-Score: 0.803196\nThreshold: 0.800\tPrecision: 0.967936\tRecall: 0.674200\tF1-Score: 0.794797\nThreshold: 0.900\tPrecision: 0.969507\tRecall: 0.659200\tF1-Score: 0.784793\n3-th iteration......\nThreshold: 0.000\tPrecision: 0.962638\tRecall: 0.900067\tF1-Score: 0.930301\nThreshold: 0.100\tPrecision: 0.962775\tRecall: 0.900067\tF1-Score: 0.930366\nThreshold: 0.200\tPrecision: 0.962981\tRecall: 0.900067\tF1-Score: 0.930462\nThreshold: 0.300\tPrecision: 0.963103\tRecall: 0.899667\tF1-Score: 0.930305\nThreshold: 0.400\tPrecision: 0.963475\tRecall: 0.896867\tF1-Score: 0.928978\nThreshold: 0.500\tPrecision: 0.963563\tRecall: 0.888533\tF1-Score: 0.924528\nThreshold: 0.600\tPrecision: 0.964352\tRecall: 0.865667\tF1-Score: 0.912348\nThreshold: 0.700\tPrecision: 0.963926\tRecall: 0.828333\tF1-Score: 0.891000\nThreshold: 0.800\tPrecision: 0.963157\tRecall: 0.782533\tF1-Score: 0.863501\nThreshold: 0.900\tPrecision: 0.964457\tRecall: 0.736267\tF1-Score: 0.835053\n4-th iteration......\nThreshold: 0.000\tPrecision: 0.963526\tRecall: 0.912267\tF1-Score: 0.937196\nThreshold: 0.100\tPrecision: 0.963526\tRecall: 0.912267\tF1-Score: 0.937196\nThreshold: 0.200\tPrecision: 0.963526\tRecall: 0.912267\tF1-Score: 0.937196\nThreshold: 0.300\tPrecision: 0.963524\tRecall: 0.912200\tF1-Score: 0.937160\nThreshold: 0.400\tPrecision: 0.963586\tRecall: 0.912067\tF1-Score: 0.937119\nThreshold: 0.500\tPrecision: 0.963749\tRecall: 0.911000\tF1-Score: 0.936633\nThreshold: 0.600\tPrecision: 0.963981\tRecall: 0.904600\tF1-Score: 0.933347\nThreshold: 0.700\tPrecision: 0.963447\tRecall: 0.880333\tF1-Score: 0.920017\nThreshold: 0.800\tPrecision: 0.962364\tRecall: 0.840400\tF1-Score: 0.897256\nThreshold: 0.900\tPrecision: 0.962628\tRecall: 0.795067\tF1-Score: 0.870861\n5-th iteration......\nThreshold: 0.000\tPrecision: 0.964804\tRecall: 0.917400\tF1-Score: 0.940505\nThreshold: 0.100\tPrecision: 0.964872\tRecall: 0.917400\tF1-Score: 0.940537\nThreshold: 0.200\tPrecision: 0.964872\tRecall: 0.917400\tF1-Score: 0.940537\nThreshold: 0.300\tPrecision: 0.964872\tRecall: 0.917400\tF1-Score: 0.940537\nThreshold: 0.400\tPrecision: 0.964872\tRecall: 0.917400\tF1-Score: 0.940537\nThreshold: 0.500\tPrecision: 0.964990\tRecall: 0.916933\tF1-Score: 0.940348\nThreshold: 0.600\tPrecision: 0.965082\tRecall: 0.912067\tF1-Score: 0.937826\nThreshold: 0.700\tPrecision: 0.964441\tRecall: 0.889600\tF1-Score: 0.925510\nThreshold: 0.800\tPrecision: 0.963298\tRecall: 0.852133\tF1-Score: 0.904312\nThreshold: 0.900\tPrecision: 0.963755\tRecall: 0.804800\tF1-Score: 0.877134\n6-th iteration......\nThreshold: 0.000\tPrecision: 0.964773\tRecall: 0.918400\tF1-Score: 0.941016\nThreshold: 0.100\tPrecision: 0.964841\tRecall: 0.918400\tF1-Score: 0.941048\nThreshold: 0.200\tPrecision: 0.964841\tRecall: 0.918400\tF1-Score: 0.941048\nThreshold: 0.300\tPrecision: 0.964841\tRecall: 0.918400\tF1-Score: 0.941048\nThreshold: 0.400\tPrecision: 0.964841\tRecall: 0.918400\tF1-Score: 0.941048\nThreshold: 0.500\tPrecision: 0.964959\tRecall: 0.917933\tF1-Score: 0.940859\nThreshold: 0.600\tPrecision: 0.965063\tRecall: 0.913400\tF1-Score: 0.938521\nThreshold: 0.700\tPrecision: 0.964425\tRecall: 0.891000\tF1-Score: 0.926260\nThreshold: 0.800\tPrecision: 0.963367\tRecall: 0.853800\tF1-Score: 0.905280\nThreshold: 0.900\tPrecision: 0.963828\tRecall: 0.806467\tF1-Score: 0.878153\n7-th iteration......\nThreshold: 0.000\tPrecision: 0.965073\tRecall: 0.919200\tF1-Score: 0.941578\nThreshold: 0.100\tPrecision: 0.965141\tRecall: 0.919200\tF1-Score: 0.941610\nThreshold: 0.200\tPrecision: 0.965141\tRecall: 0.919200\tF1-Score: 0.941610\nThreshold: 0.300\tPrecision: 0.965141\tRecall: 0.919200\tF1-Score: 0.941610\nThreshold: 0.400\tPrecision: 0.965141\tRecall: 0.919200\tF1-Score: 0.941610\nThreshold: 0.500\tPrecision: 0.965256\tRecall: 0.918667\tF1-Score: 0.941385\nThreshold: 0.600\tPrecision: 0.965364\tRecall: 0.914200\tF1-Score: 0.939086\nThreshold: 0.700\tPrecision: 0.964731\tRecall: 0.891733\tF1-Score: 0.926797\nThreshold: 0.800\tPrecision: 0.963631\tRecall: 0.854933\tF1-Score: 0.906034\nThreshold: 0.900\tPrecision: 0.964101\tRecall: 0.807467\tF1-Score: 0.878859\n8-th iteration......\nThreshold: 0.000\tPrecision: 0.965351\tRecall: 0.919400\tF1-Score: 0.941815\nThreshold: 0.100\tPrecision: 0.965418\tRecall: 0.919400\tF1-Score: 0.941847\nThreshold: 0.200\tPrecision: 0.965418\tRecall: 0.919400\tF1-Score: 0.941847\nThreshold: 0.300\tPrecision: 0.965418\tRecall: 0.919400\tF1-Score: 0.941847\nThreshold: 0.400\tPrecision: 0.965418\tRecall: 0.919400\tF1-Score: 0.941847\nThreshold: 0.500\tPrecision: 0.965534\tRecall: 0.918867\tF1-Score: 0.941623\nThreshold: 0.600\tPrecision: 0.965643\tRecall: 0.914400\tF1-Score: 0.939323\nThreshold: 0.700\tPrecision: 0.965027\tRecall: 0.892200\tF1-Score: 0.927186\nThreshold: 0.800\tPrecision: 0.963873\tRecall: 0.855533\tF1-Score: 0.906477\nThreshold: 0.900\tPrecision: 0.964360\tRecall: 0.808133\tF1-Score: 0.879362\n9-th iteration......\nThreshold: 0.000\tPrecision: 0.965430\tRecall: 0.919733\tF1-Score: 0.942028\nThreshold: 0.100\tPrecision: 0.965498\tRecall: 0.919733\tF1-Score: 0.942060\nThreshold: 0.200\tPrecision: 0.965498\tRecall: 0.919733\tF1-Score: 0.942060\nThreshold: 0.300\tPrecision: 0.965498\tRecall: 0.919733\tF1-Score: 0.942060\nThreshold: 0.400\tPrecision: 0.965498\tRecall: 0.919733\tF1-Score: 0.942060\nThreshold: 0.500\tPrecision: 0.965614\tRecall: 0.919200\tF1-Score: 0.941835\nThreshold: 0.600\tPrecision: 0.965724\tRecall: 0.914733\tF1-Score: 0.939537\nThreshold: 0.700\tPrecision: 0.965174\tRecall: 0.892400\tF1-Score: 0.927362\nThreshold: 0.800\tPrecision: 0.964028\tRecall: 0.855800\tF1-Score: 0.906696\nThreshold: 0.900\tPrecision: 0.964524\tRecall: 0.808400\tF1-Score: 0.879588\n10-th iteration......\nThreshold: 0.000\tPrecision: 0.965223\tRecall: 0.919600\tF1-Score: 0.941859\nThreshold: 0.100\tPrecision: 0.965290\tRecall: 0.919600\tF1-Score: 0.941891\nThreshold: 0.200\tPrecision: 0.965290\tRecall: 0.919600\tF1-Score: 0.941891\nThreshold: 0.300\tPrecision: 0.965290\tRecall: 0.919600\tF1-Score: 0.941891\nThreshold: 0.400\tPrecision: 0.965290\tRecall: 0.919600\tF1-Score: 0.941891\nThreshold: 0.500\tPrecision: 0.965406\tRecall: 0.919067\tF1-Score: 0.941667\nThreshold: 0.600\tPrecision: 0.965515\tRecall: 0.914600\tF1-Score: 0.939368\nThreshold: 0.700\tPrecision: 0.964963\tRecall: 0.892333\tF1-Score: 0.927228\nThreshold: 0.800\tPrecision: 0.963878\tRecall: 0.855667\tF1-Score: 0.906555\nThreshold: 0.900\tPrecision: 0.964365\tRecall: 0.808267\tF1-Score: 0.879443\nPARIS Completed!\nTotal time: 310.86228489875793\ntraining size: 14290\ttest size: 710\n","output_type":"stream"}]}]}