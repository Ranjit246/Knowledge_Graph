{"metadata":{"colab":{"provenance":[],"private_outputs":true,"collapsed_sections":["do2yT94Yagds","HM0ax6rPpbpe","ZTE3qGJ-qPcX","1xP_BA1Gmto3"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU","language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Install AmpliGraph and other dependencies","metadata":{"id":"UM6Awy5WFUVA"}},{"cell_type":"markdown","source":"Ampligraph is a Library for Representation Learning on Knowledge Graphs. For Discovering new knowledge from an existing knowledge graph, Complete large knowledge graphs with missing statements, Generate stand-alone knowledge graph embeddings and evaluate a new relational model are some of the usecases of Ampligraph module.","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow==1.15.0\nimport tensorflow as tf \n\nprint('TensorFlow  version: {}'.format(tf.__version__))","metadata":{"id":"vs4xn9CWE5Yx","execution":{"iopub.status.busy":"2022-12-25T18:36:08.380400Z","iopub.execute_input":"2022-12-25T18:36:08.381168Z","iopub.status.idle":"2022-12-25T18:37:17.625492Z","shell.execute_reply.started":"2022-12-25T18:36:08.381023Z","shell.execute_reply":"2022-12-25T18:37:17.623870Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==1.15.0\n  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.3.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.37.1)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.2.0)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.21.6)\nCollecting tensorflow-estimator==1.15.1\n  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.4/503.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.2)\nCollecting keras-applications>=1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nCollecting tensorboard<1.16.0,>=1.15.0\n  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.12.1)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.15.0)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.19.4)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.0)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.15.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.43.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.7.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (59.8.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.2.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.7)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.13.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.4.0)\nBuilding wheels for collected packages: gast\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=705038a4f1117b01571e9fe400b0af9b7f8a2dbd7b0a27c8278b4b8c3318dbff\n  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\nSuccessfully built gast\nInstalling collected packages: tensorflow-estimator, gast, astor, keras-applications, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: gast\n    Found existing installation: gast 0.4.0\n    Uninstalling gast-0.4.0:\n      Successfully uninstalled gast-0.4.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.10.1\n    Uninstalling tensorboard-2.10.1:\n      Successfully uninstalled tensorboard-2.10.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.4\n    Uninstalling tensorflow-2.6.4:\n      Successfully uninstalled tensorflow-2.6.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 1.15.0 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 1.15.0 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 1.15.0 which is incompatible.\ntensorflow-probability 0.14.1 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 1.15.0 which is incompatible.\ntensorflow-decision-forests 0.2.0 requires tensorflow~=2.6, but you have tensorflow 1.15.0 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorboard>=2.3.0, but you have tensorboard 1.15.0 which is incompatible.\npytorch-lightning 1.7.7 requires tensorboard>=2.9.1, but you have tensorboard 1.15.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed astor-0.8.1 gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mTensorFlow  version: 1.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture \n# Install AmpliGraph library\n! pip install ampligraph\n\n# Required to visualize embeddings with tensorboard projector, comment out if not required!\n! pip install --user tensorboard\n\n# Required to plot text on embedding clusters, comment out if not required!\n! pip install --user git+https://github.com/Phlya/adjustText","metadata":{"id":"Lgs8cTcu9hUM","execution":{"iopub.status.busy":"2022-12-25T18:37:17.628188Z","iopub.execute_input":"2022-12-25T18:37:17.628596Z","iopub.status.idle":"2022-12-25T18:38:04.682442Z","shell.execute_reply.started":"2022-12-25T18:37:17.628558Z","shell.execute_reply":"2022-12-25T18:38:04.681436Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# All imports used in this tutorial \n# %tensorflow_version 1.15\nimport ampligraph\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom ampligraph.datasets import load_fb15k_237\nfrom ampligraph.evaluation import train_test_split_no_unseen, evaluate_performance, mr_score, mrr_score, hits_at_n_score\nfrom ampligraph.discovery import query_topn, discover_facts, find_clusters\nfrom ampligraph.latent_features import TransE, ComplEx, HolE, DistMult, ConvE, ConvKB\nfrom ampligraph.utils import save_model, restore_model\n\ndef display_aggregate_metrics(ranks):\n    print('Mean Rank:', mr_score(ranks)) \n    print('Mean Reciprocal Rank:', mrr_score(ranks)) \n    print('Hits@1:', hits_at_n_score(ranks, 1))\n    print('Hits@10:', hits_at_n_score(ranks, 10))\n    print('Hits@100:', hits_at_n_score(ranks, 100))\n\nprint('Ampligraph version: {}'.format(ampligraph.__version__))","metadata":{"id":"KqGjJ_SYFxIH","execution":{"iopub.status.busy":"2022-12-25T18:38:04.684106Z","iopub.execute_input":"2022-12-25T18:38:04.684688Z","iopub.status.idle":"2022-12-25T18:38:06.312588Z","shell.execute_reply.started":"2022-12-25T18:38:04.684644Z","shell.execute_reply":"2022-12-25T18:38:06.311702Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Ampligraph version: 1.4.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Loading a Knowledge Graph dataset\n\nTo begin with we're going to need a knowledge graph, so let's load a standard knowledge graph called ***Freebase-15k-237***. Used APIs from Ampligraph to load the freebase-15k-237 dataset.\n","metadata":{"id":"E2zQO7QqjYQW"}},{"cell_type":"code","source":"from ampligraph.datasets import load_fb15k_237","metadata":{"id":"IYLn3NXKegOm","execution":{"iopub.status.busy":"2022-12-25T18:38:06.315010Z","iopub.execute_input":"2022-12-25T18:38:06.315328Z","iopub.status.idle":"2022-12-25T18:38:06.319445Z","shell.execute_reply.started":"2022-12-25T18:38:06.315303Z","shell.execute_reply":"2022-12-25T18:38:06.318542Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"\nFor this tutorial we have remapped the IDs of freebase 237 and created a csv file containing human readable names instead of IDs. Following is a sample of the dataset.","metadata":{"id":"MKrD7K04egPS"}},{"cell_type":"code","source":"import pandas as pd\n\nURL = 'https://ampgraphenc.s3-eu-west-1.amazonaws.com/datasets/freebase-237-merged-and-remapped.csv'\ndataset = pd.read_csv(URL, header=None)\ndataset.columns = ['subject', 'predicate', 'object']\ndataset.head(5)","metadata":{"id":"cHzhvBhbegPX","execution":{"iopub.status.busy":"2022-12-25T18:38:06.321430Z","iopub.execute_input":"2022-12-25T18:38:06.321978Z","iopub.status.idle":"2022-12-25T18:38:07.363114Z","shell.execute_reply.started":"2022-12-25T18:38:06.321946Z","shell.execute_reply":"2022-12-25T18:38:07.361874Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                       subject  \\\n0  queens college, city university of new york   \n1                digital equipment corporation   \n2                                    /m/0drtv8   \n3                                 the departed   \n4                               marilyn manson   \n\n                                           predicate             object  \n0  /education/educational_institution/students_gr...       carol leifer  \n1              /business/business_operation/industry  computer hardware  \n2  /award/award_ceremony/awards_presented./award/...      laurence mark  \n3  /award/award_winning_work/awards_won./award/aw...  leonardo dicaprio  \n4                          /people/person/profession              actor  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>predicate</th>\n      <th>object</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>queens college, city university of new york</td>\n      <td>/education/educational_institution/students_gr...</td>\n      <td>carol leifer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>digital equipment corporation</td>\n      <td>/business/business_operation/industry</td>\n      <td>computer hardware</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/m/0drtv8</td>\n      <td>/award/award_ceremony/awards_presented./award/...</td>\n      <td>laurence mark</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the departed</td>\n      <td>/award/award_winning_work/awards_won./award/aw...</td>\n      <td>leonardo dicaprio</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>marilyn manson</td>\n      <td>/people/person/profession</td>\n      <td>actor</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print('Total triples in the KG:', dataset.shape)","metadata":{"id":"4pgpcidHegQC","execution":{"iopub.status.busy":"2022-12-25T18:38:07.364480Z","iopub.execute_input":"2022-12-25T18:38:07.364796Z","iopub.status.idle":"2022-12-25T18:38:07.370845Z","shell.execute_reply.started":"2022-12-25T18:38:07.364765Z","shell.execute_reply":"2022-12-25T18:38:07.369329Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total triples in the KG: (310079, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n![KG](https://user-images.githubusercontent.com/39597669/90747195-9fc44c80-e2c8-11ea-9f70-097993581bac.png) \n","metadata":{"id":"flR0xOXmegP9"}},{"cell_type":"markdown","source":"\n## 2.1 Create training, validation and test splits\n\nLet's use the [`train_test_split_no_unseen`](https://docs.ampligraph.org/en/1.3.1/generated/ampligraph.evaluation.train_test_split_no_unseen.html?#train-test-split-no-unseen) function provided by Ampligraph to create the training, validation and test splits. \n\nThis API ensures that the test and validation splits contains triples whose entities are \"seen\" during training. \n","metadata":{"id":"PQJkziMCegQL"}},{"cell_type":"code","source":"from ampligraph.evaluation import train_test_split_no_unseen\n# get the validation set of size 500\ntest_train, X_valid = train_test_split_no_unseen(dataset.values, 500, seed=0)\n\n# get the test set of size 1000 from the remaining triples\nX_train, X_test = train_test_split_no_unseen(test_train, 1000, seed=0)\n\nprint('Total triples:', dataset.shape)\nprint('Size of train:', X_train.shape)\nprint('Size of valid:', X_valid.shape)\nprint('Size of test:', X_test.shape)","metadata":{"id":"ltijAdQtegQN","execution":{"iopub.status.busy":"2022-12-25T18:38:07.372230Z","iopub.execute_input":"2022-12-25T18:38:07.372551Z","iopub.status.idle":"2022-12-25T18:38:09.007413Z","shell.execute_reply.started":"2022-12-25T18:38:07.372521Z","shell.execute_reply":"2022-12-25T18:38:09.006381Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total triples: (310079, 3)\nSize of train: (308579, 3)\nSize of valid: (500, 3)\nSize of test: (1000, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"`train_test_split_no_unseen` API can be used to generate train/test splits such that test set contains only entities 'seen' during training","metadata":{"id":"4Q38cXnYHHI6"}},{"cell_type":"markdown","source":"# 3. Model Training\nNow that we have split the dataset, let's dive directly into model training. \n\nLet us create a TransE model and train it on the training split using the `fit` function.\n\n**TransE** is one of the first embedding models which set the platform for the KGE research. It uses simple vector algebra to score the triples. It has very low number of trainable parameters compared to most models. \n","metadata":{"id":"fgAcQ1g3egQe"}},{"cell_type":"code","source":"from ampligraph.latent_features import TransE\n\nmodel = TransE(k=150,                                                             # embedding size\n               epochs=100,                                                        # Num of epochs\n               batches_count= 10,                                                 # Number of batches \n               eta=1,                                                             # number of corruptions to generate during training\n               loss='pairwise', loss_params={'margin': 1},                        # loss type and it's hyperparameters         \n               initializer='xavier', initializer_params={'uniform': False},       # initializer type and it's hyperparameters\n               regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},   # regularizer along with its hyperparameters\n               optimizer= 'adam', optimizer_params= {'lr': 0.001},                # optimizer to use along with its hyperparameters\n               seed= 0, verbose=True)\n\nmodel.fit(X_train)\n\nfrom ampligraph.utils import save_model, restore_model\nsave_model(model, 'TransE-small.pkl')","metadata":{"id":"ap1Yd4LEegQg","execution":{"iopub.status.busy":"2022-12-25T18:38:09.008640Z","iopub.execute_input":"2022-12-25T18:38:09.009750Z","iopub.status.idle":"2022-12-25T18:38:57.798224Z","shell.execute_reply.started":"2022-12-25T18:38:09.009707Z","shell.execute_reply":"2022-12-25T18:38:57.795793Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2022-12-25 18:38:09.836600: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2022-12-25 18:38:09.842589: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2249995000 Hz\n2022-12-25 18:38:09.843065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b761c96660 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2022-12-25 18:38:09.843113: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2022-12-25 18:38:09.844757: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2022-12-25 18:38:09.844855: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n2022-12-25 18:38:09.844895: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f85b094377ed): /proc/driver/nvidia/version does not exist\nAverage TransE Loss:   0.013602: 100%|██████████| 100/100 [00:47<00:00,  2.11epoch/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3.1 Compute the evaluation metrics\n\n### Per triple metrics:\nThis is a metric that is computed for each test set triple:\n\n- **score**: This is the value assigned to a triple, by the model, by applying the scoring function.\n\nLet's look at how we can get the score for a triple of interest and how to interpret it.\n","metadata":{"id":"JaJeVr-megQq"}},{"cell_type":"code","source":"test_triple = ['harrison ford', \n               '/film/actor/film./film/performance/film', \n               'star wars']\n\ntriple_score = model.predict(test_triple)\n\nprint('Triple of interest:\\n', test_triple)\nprint('Triple Score:\\n', triple_score)","metadata":{"id":"edjJcTReegQs","execution":{"iopub.status.busy":"2022-12-25T18:38:57.800723Z","iopub.execute_input":"2022-12-25T18:38:57.801095Z","iopub.status.idle":"2022-12-25T18:38:57.880121Z","shell.execute_reply.started":"2022-12-25T18:38:57.801036Z","shell.execute_reply":"2022-12-25T18:38:57.879465Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Triple of interest:\n ['harrison ford', '/film/actor/film./film/performance/film', 'star wars']\nTriple Score:\n [-8.319288]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"But what does this score tell you? Nothing! It is just a value. In order to interpret the score we have 2 options:\n\n1. We can create a list of hypothesis that we want to test, score them and then choose the top n hypothesis as True statements.\n\n2. As described earlier in the theory section, unlike classification task, we are doing a learning to rank task. In order to interpret the score we can generate the corruptions and compare the triple score against the scores of corruptions to see how well does the model rank the test triple against them.\n\n\nLet's look at the first option. Let us create a list of hypothesis and score them.","metadata":{"id":"mQwswE4qFArO"}},{"cell_type":"code","source":"import numpy as np\nlist_of_actors = ['salma hayek', 'carrie fisher', 'natalie portman',  'kristen bell',\n                  'mark hamill', 'neil patrick harris', 'harrison ford' ]\n\n# stack it horizontally to create s, p, o\nhypothesis = np.column_stack([list_of_actors, \n                              ['/film/actor/film./film/performance/film'] * len(list_of_actors),\n                              ['star wars'] * len(list_of_actors),\n                             ])\n\n# score the hypothesis\ntriple_scores = model.predict(hypothesis)\n\n# append the scores column\nscored_hypothesis = np.column_stack([hypothesis, triple_scores])\n# sort by score in descending order\nscored_hypothesis = scored_hypothesis[np.argsort(scored_hypothesis[:, 3])]\nscored_hypothesis","metadata":{"id":"zKewmQmp-1od","execution":{"iopub.status.busy":"2022-12-25T18:38:57.883195Z","iopub.execute_input":"2022-12-25T18:38:57.883704Z","iopub.status.idle":"2022-12-25T18:38:57.962080Z","shell.execute_reply.started":"2022-12-25T18:38:57.883674Z","shell.execute_reply":"2022-12-25T18:38:57.960710Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([['natalie portman', '/film/actor/film./film/performance/film',\n        'star wars', '-8.30834'],\n       ['harrison ford', '/film/actor/film./film/performance/film',\n        'star wars', '-8.319288'],\n       ['carrie fisher', '/film/actor/film./film/performance/film',\n        'star wars', '-9.085773'],\n       ['neil patrick harris', '/film/actor/film./film/performance/film',\n        'star wars', '-9.246227'],\n       ['salma hayek', '/film/actor/film./film/performance/film',\n        'star wars', '-9.3796625'],\n       ['kristen bell', '/film/actor/film./film/performance/film',\n        'star wars', '-9.537163'],\n       ['mark hamill', '/film/actor/film./film/performance/film',\n        'star wars', '-9.568335']], dtype='<U39')"},"metadata":{}}]},{"cell_type":"markdown","source":"\n- **rank**: For a triple, this metric is computed by generating corruptions and then scoring them and computing the rank(position) of the triple score against the corruptions. The pseudocode and the example illustrates how to compute rank on the test set.\n\n         for each test set triple <s, p, o>:\n                 a. Compute the score of the test triple (hypothesis) \n                     hypothesis_score = score(<s, p, o>)\n                     \n                 b. Generate the subject corruptions \n                         sub_corr = <?, p, o>\n                 c. Compute the score of the subject corruptions\n                         sub_corr_score = score(sub_corr) \n                 d. Find the position of hypothesis_score in sub_corr_score to get the sub_rank\n                   \n                 e. Generate the object corruption \n                         obj_corr = <s, p, ?>\n                 f. Compute the score of the object corruptions\n                         obj_corr_score = score(obj_corr) \n                 g. Find the position of hypothesis_score in obj_corr_score to get the obj_rank\n                 \n                 h. Return rank = [sub_rank, obj_rank]\n\n\n\n![rank example](https://user-images.githubusercontent.com/281477/90627614-14897f00-e214-11ea-8f8e-d57da9888606.png)\n\n\n\n","metadata":{"id":"4UUNCR-p_EmC"}},{"cell_type":"markdown","source":"### Illustrative Example ","metadata":{"id":"do2yT94Yagds"}},{"cell_type":"markdown","source":"**Compute the score of the test triple**","metadata":{"id":"dImehz68LHQh"}},{"cell_type":"code","source":"test_triple = ['harrison ford', \n               '/film/actor/film./film/performance/film', \n               'star wars']\n\ntriple_score = model.predict(test_triple)\n\nprint('Triple of interest:\\n', test_triple)\nprint('Triple Score:\\n', triple_score)","metadata":{"id":"dpRVBVn_K-_S","execution":{"iopub.status.busy":"2022-12-25T18:38:57.963334Z","iopub.execute_input":"2022-12-25T18:38:57.963644Z","iopub.status.idle":"2022-12-25T18:38:58.038651Z","shell.execute_reply.started":"2022-12-25T18:38:57.963615Z","shell.execute_reply":"2022-12-25T18:38:58.036982Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Triple of interest:\n ['harrison ford', '/film/actor/film./film/performance/film', 'star wars']\nTriple Score:\n [-8.319288]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Before generating the corruptions, let us look at the number of unique entities present in our dataset","metadata":{"id":"SlLprqLE_Hby"}},{"cell_type":"code","source":"print('The number of unique entities:', len(model.ent_to_idx))","metadata":{"id":"PMEBkOW1VoOS","execution":{"iopub.status.busy":"2022-12-25T18:38:58.076823Z","iopub.execute_input":"2022-12-25T18:38:58.077332Z","iopub.status.idle":"2022-12-25T18:38:58.084278Z","shell.execute_reply.started":"2022-12-25T18:38:58.077280Z","shell.execute_reply":"2022-12-25T18:38:58.083107Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"The number of unique entities: 14184\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Generate the subject *corruptions* and compute rank**\n> ```sub_corr = <?, p, o>```","metadata":{"id":"UXBikfbWkuK6"}},{"cell_type":"code","source":"subj_corr =  np.column_stack([list(model.ent_to_idx.keys()),\n                [test_triple[1]] * len(model.ent_to_idx), \n                [test_triple[2]] * len(model.ent_to_idx)])\n\nprint('Subject corruptions:\\n', subj_corr)\nprint('\\nSize of subject corruptions:\\n', subj_corr.shape)","metadata":{"id":"WE6lw5FB_I_4","execution":{"iopub.status.busy":"2022-12-25T18:38:58.087550Z","iopub.execute_input":"2022-12-25T18:38:58.087855Z","iopub.status.idle":"2022-12-25T18:38:58.111020Z","shell.execute_reply.started":"2022-12-25T18:38:58.087824Z","shell.execute_reply":"2022-12-25T18:38:58.109527Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Subject corruptions:\n [['/m/011xg5' '/film/actor/film./film/performance/film' 'star wars']\n ['/m/011yd2' '/film/actor/film./film/performance/film' 'star wars']\n ['/m/011yxg' '/film/actor/film./film/performance/film' 'star wars']\n ...\n ['zoology' '/film/actor/film./film/performance/film' 'star wars']\n ['zurich' '/film/actor/film./film/performance/film' 'star wars']\n ['zz top' '/film/actor/film./film/performance/film' 'star wars']]\n\nSize of subject corruptions:\n (14184, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Compute the score of the subject corruptions**","metadata":{"id":"vO1HXo4x7t2R"}},{"cell_type":"code","source":"sub_corr_score = model.predict(subj_corr)\nsub_corr_score","metadata":{"id":"N65INkWR_LFx","execution":{"iopub.status.busy":"2022-12-25T18:38:58.112979Z","iopub.execute_input":"2022-12-25T18:38:58.113447Z","iopub.status.idle":"2022-12-25T18:38:58.215038Z","shell.execute_reply.started":"2022-12-25T18:38:58.113403Z","shell.execute_reply":"2022-12-25T18:38:58.214097Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([-11.120162, -10.320112, -11.608588, ...,  -8.708649, -10.551394,\n        -8.945932], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"Now that we have a score, let us compute the rank as follows:\n\n<center>$COUNT ( corruption_{score} >= triple_{score} )$</center>\n\nFind the position of hypothesis_score in sub_corr_score to get the sub_rank","metadata":{"id":"Vu7vlKdg_OoM"}},{"cell_type":"code","source":"sub_rank_worst = np.sum(np.greater_equal(sub_corr_score, triple_score[0])) + 1\n\nprint('Assigning the worst rank (to break ties):', sub_rank_worst)","metadata":{"id":"V070u2N2_NBM","execution":{"iopub.status.busy":"2022-12-25T18:38:58.216461Z","iopub.execute_input":"2022-12-25T18:38:58.216787Z","iopub.status.idle":"2022-12-25T18:38:58.223149Z","shell.execute_reply.started":"2022-12-25T18:38:58.216756Z","shell.execute_reply":"2022-12-25T18:38:58.221825Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Assigning the worst rank (to break ties): 1674\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Generate the object *corruptions* and compute rank**\n\n>    ``` obj_corr = <s, p, ?> ```\n","metadata":{"id":"ADOTNTGakqAO"}},{"cell_type":"code","source":"obj_corr =  np.column_stack([\n                [test_triple[0]] * len(model.ent_to_idx),\n                [test_triple[1]] * len(model.ent_to_idx), \n                     list(model.ent_to_idx.keys())])\n\n\nprint('Object corruptions:\\n', obj_corr)\nprint('\\nSize of object corruptions:\\n', obj_corr.shape)\n\n# f. Compute the score of the object corruptions\nobj_corr_score = model.predict(obj_corr)\n\n# g. Find the position of hypothesis_score in obj_corr_score to get the obj_rank\nobj_rank_worst = np.sum(np.less_equal(triple_score[0], obj_corr_score)) + 1\nprint('Assigning the worst rank (to break ties):', obj_rank_worst)\n","metadata":{"id":"1MBRrCM0_RRB","execution":{"iopub.status.busy":"2022-12-25T18:38:58.224810Z","iopub.execute_input":"2022-12-25T18:38:58.225266Z","iopub.status.idle":"2022-12-25T18:38:58.349078Z","shell.execute_reply.started":"2022-12-25T18:38:58.225223Z","shell.execute_reply":"2022-12-25T18:38:58.348128Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Object corruptions:\n [['harrison ford' '/film/actor/film./film/performance/film' '/m/011xg5']\n ['harrison ford' '/film/actor/film./film/performance/film' '/m/011yd2']\n ['harrison ford' '/film/actor/film./film/performance/film' '/m/011yxg']\n ...\n ['harrison ford' '/film/actor/film./film/performance/film' 'zoology']\n ['harrison ford' '/film/actor/film./film/performance/film' 'zurich']\n ['harrison ford' '/film/actor/film./film/performance/film' 'zz top']]\n\nSize of object corruptions:\n (14184, 3)\nAssigning the worst rank (to break ties): 825\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Subject corruption rank:', sub_rank_worst)\nprint('Object corruption rank:', obj_rank_worst)","metadata":{"id":"F2OPFtvC_TJL","execution":{"iopub.status.busy":"2022-12-25T18:38:58.350234Z","iopub.execute_input":"2022-12-25T18:38:58.350647Z","iopub.status.idle":"2022-12-25T18:38:58.355148Z","shell.execute_reply.started":"2022-12-25T18:38:58.350620Z","shell.execute_reply":"2022-12-25T18:38:58.354206Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Subject corruption rank: 1674\nObject corruption rank: 825\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Computing the (Unfiltered) rank using evaluate_performance API**\n\nWe can use the [evaluate_performance](https://docs.ampligraph.org/en/latest/generated/ampligraph.evaluation.evaluate_performance.html) API to compute the ranks. By default, `evaluate_performance` API computes the unfiltered ranks i.e. if any true positives are present in corruptions, they will not be removed before ranking. However, usually for evaluation, we follow a filtered evaluation as described in the next section.\n","metadata":{"id":"V-d0JAxjC6ie"}},{"cell_type":"code","source":"from ampligraph.evaluation import evaluate_performance \n\nranks = evaluate_performance(np.array([test_triple]), \n                             model=model,\n                             ranking_strategy='worst')\n\nprint('\\nRanks:', ranks)","metadata":{"id":"06VnAcRyC5gk","execution":{"iopub.status.busy":"2022-12-25T18:38:58.356653Z","iopub.execute_input":"2022-12-25T18:38:58.356907Z","iopub.status.idle":"2022-12-25T18:38:58.625887Z","shell.execute_reply.started":"2022-12-25T18:38:58.356882Z","shell.execute_reply":"2022-12-25T18:38:58.625231Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 18.38it/s]","output_type":"stream"},{"name":"stdout","text":"\nRanks: [[1674  825]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"There are multiple strategies to compute ranks especially when there are ties. Lets look at each of them in detail with an example. \n\nAssume there are only 10 corruptions, and assume that all the corruptions get the same score as the test triple. The ranks are as follows \n- Assign the **worst rank** i.e. the test set triple gets a rank of 11. This is followed by most papers in the literature. This is the strictest approach and it drives down the mrr by a large margin if there are many ties. We employ this strategy in AmpliGraph.\n\n<center> $rank = COUNT( corruption_{score} \\ge hypothesis_{score} )$ + 1</center>\n    \n- Assign the **middle rank** i.e. the test set triple gets a rank of 6. We found this strategy being used by [ICLR 2020 paper](https://openreview.net/pdf?id=BkxSmlBFvr). This approach seems to be fair towards the model in resolving the ties as it assigns the middle rank to break ties.\n\n<center> $rank = COUNT( corruption_{score} \\gt hypothesis_{score} ) + \\dfrac{COUNT( corruption_{score} == hypothesis_{score} )}{2}$ + 1</center>\n\n- Assign the **best rank** i.e. the test set triple gets a rank of 1. This approach is followed by [ConvKB paper](https://arxiv.org/pdf/1712.02121.pdf).  This approach is overly biased and helps the model achieve a very good mrr in case of ties.\n\n<center> $rank = COUNT( corruption_{score} \\gt hypothesis_{score} )$ + 1</center>\n\nWe recommend the usage of the **worst** strategy (default).","metadata":{"id":"KgkpA_BWk_uo"}},{"cell_type":"markdown","source":"## 3.2 Filtered evaluation\nWhile evaluating ([as described earlier](#Compute-the-evaluation-metrics)), we generate all the corruptions (using all the unique entities in our dataset) per test triple, score and rank them. While doing so, we are not filtering the true positives - in other words, some of the corruptions may not really be corruptions and may be ground truth triples observed during training. Training triples usually get a high score as they are \"observed\" by the model. Hence a test triple would get a lower rank if such triples appear in corruptions. To filter out the True Positives (after step b. and e.), one can pass all the True Positive triples  to `filter_triples` parameter of the `evaluate_performance` API. This will perform a **\"filtered\" evaluation** and return the **\"filtered\" ranks** adjusted by removing the True Positives from the corruptions. More details for `evaluate_performance` API can be found [here](https://docs.ampligraph.org/en/latest/generated/ampligraph.evaluation.evaluate_performance.html#ampligraph.evaluation.evaluate_performance).\n","metadata":{"id":"PuJpqTDklDux"}},{"cell_type":"code","source":"from ampligraph.evaluation import evaluate_performance \n\nprint('Size of X_test:', X_test.shape)\n\nX_filter = np.concatenate([X_train, X_valid, X_test], 0)\n\nranks = evaluate_performance(np.array([test_triple]), \n                             model=model,\n                             filter_triples=X_filter)\n\nprint(ranks)","metadata":{"id":"YLD9MgxkC5Oo","execution":{"iopub.status.busy":"2022-12-25T18:38:58.626843Z","iopub.execute_input":"2022-12-25T18:38:58.627666Z","iopub.status.idle":"2022-12-25T18:39:03.298839Z","shell.execute_reply.started":"2022-12-25T18:38:58.627636Z","shell.execute_reply":"2022-12-25T18:39:03.297297Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Size of X_test: (1000, 3)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 14.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"[[1663  815]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"One obvious question is why do we append the Valid and Test set to the X_filter. The model has not \"observed\" them during training. We do so because, we would like to evaluate a test triple against it's corruptions and not against known facts. If we know that the Validation triples and Test triples are facts (and not queries), we need to filter these triples out of the generated corruptions. This is the standard procedure that is used to compute the metrics to compete on the leadership board.","metadata":{"id":"CdAw7EUMlYon"}},{"cell_type":"markdown","source":"## 3.3 Aggregate metrics\n\n\nOnce we have the ranks for all the test set triples, we can compute the following aggregate metrics: **MR**, **MRR**, **Hits@N**. These metrics indicate the overall quality of the model on a test set. These metrics come from Information Retrieval domain and are always computed on a set of **True Statements**. To illustrate each of these metric let us first create a small test set of 5 triples and compute their ranks.","metadata":{"id":"W_YEKhYglae3"}},{"cell_type":"code","source":"X_test_small = np.array(\n                [['doctorate',\n                    '/education/educational_degree/people_with_this_degree./education/education/major_field_of_study',\n                    'computer engineering'],\n\n                ['star wars',\n                    '/film/film/estimated_budget./measurement_unit/dated_money_value/currency',\n                    'united states dollar'],\n\n                ['harry potter and the chamber of secrets',\n                    '/film/film/estimated_budget./measurement_unit/dated_money_value/currency',\n                    'united states dollar'],\n\n                ['star wars', '/film/film/language', 'english language'],\n                ['harrison ford', '/film/actor/film./film/performance/film', 'star wars']])\n\n\nX_filter = np.concatenate([X_train, X_valid, X_test], 0)\n\nranks = evaluate_performance(X_test_small, \n                             model=model, \n                             filter_triples=X_filter, \n                             corrupt_side='s,o')\nprint(ranks)","metadata":{"id":"ZXe0FgPeC_Si","execution":{"iopub.status.busy":"2022-12-25T18:39:03.300558Z","iopub.execute_input":"2022-12-25T18:39:03.300927Z","iopub.status.idle":"2022-12-25T18:39:07.603458Z","shell.execute_reply.started":"2022-12-25T18:39:03.300891Z","shell.execute_reply":"2022-12-25T18:39:07.602116Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|██████████| 5/5 [00:00<00:00, 47.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"[[  10   10]\n [   2    1]\n [  23    1]\n [   1    1]\n [1663  815]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now let us look at each aggregate metrics in detail:\n\n- **Mean rank (MR)**, as the name indicates, is the average of all the ranks of the triples. The value ranges from 1 (ideal case when all ranks equal to 1) to number of corruptions (where all the ranks are last).\n\n![mr formula](https://user-images.githubusercontent.com/281477/90627586-105d6180-e214-11ea-84d4-c5d3e4b089f4.png)","metadata":{"id":"KKy0b0XVlgRY"}},{"cell_type":"code","source":"from ampligraph.evaluation import mr_score\nprint('MR :', mr_score(ranks))","metadata":{"id":"7aaCDgkFldn6","execution":{"iopub.status.busy":"2022-12-25T18:39:07.604864Z","iopub.execute_input":"2022-12-25T18:39:07.605571Z","iopub.status.idle":"2022-12-25T18:39:07.611274Z","shell.execute_reply.started":"2022-12-25T18:39:07.605538Z","shell.execute_reply":"2022-12-25T18:39:07.609903Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"MR : 252.7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- **Mean reciprocal rank (MRR)**, is the average of the reciprocal ranks of all the triples. The value ranges from 0 to 1; higher the value better is the model.\n\n![mrr formula](https://user-images.githubusercontent.com/281477/90627604-12272500-e214-11ea-9777-5d30b23f0d6f.png)","metadata":{"id":"bDyhtqxYYMmv"}},{"cell_type":"code","source":"from ampligraph.evaluation import mrr_score\nprint('MRR :', mrr_score(ranks))","metadata":{"id":"8El8j03AYL5d","execution":{"iopub.status.busy":"2022-12-25T18:39:07.612844Z","iopub.execute_input":"2022-12-25T18:39:07.613252Z","iopub.status.idle":"2022-12-25T18:39:07.628185Z","shell.execute_reply.started":"2022-12-25T18:39:07.613219Z","shell.execute_reply":"2022-12-25T18:39:07.626185Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"MRR : 0.4745306577645\n","output_type":"stream"}]},{"cell_type":"markdown","source":"MRR is an indicator of mean rank after removing the effect of outliers.","metadata":{"id":"Wcw8Sgc3lmPc"}},{"cell_type":"code","source":"print('Mean rank after removing the outlier effect: ', np.ceil(1/mrr_score(ranks)))","metadata":{"id":"cbWTp59JlnaH","execution":{"iopub.status.busy":"2022-12-25T18:39:07.629809Z","iopub.execute_input":"2022-12-25T18:39:07.631076Z","iopub.status.idle":"2022-12-25T18:39:07.643741Z","shell.execute_reply.started":"2022-12-25T18:39:07.631016Z","shell.execute_reply":"2022-12-25T18:39:07.641956Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Mean rank after removing the outlier effect:  3.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- **hits@n** is the percentage of computed ranks that are greater than (in terms of ranking) or equal to a rank of n. The value ranges from 0 to 1; higher the value better is the model.\n\n![hits formula](https://user-images.githubusercontent.com/281477/90627565-09365380-e214-11ea-81c8-292a3de016d0.png)","metadata":{"id":"3d_YGuEJlpxw"}},{"cell_type":"code","source":"from ampligraph.evaluation import hits_at_n_score\nprint('hits@1 :', hits_at_n_score(ranks, 1))\nprint('hits@3 :', hits_at_n_score(ranks, 3))\nprint('hits@5 :', hits_at_n_score(ranks, 5))\nprint('hits@10 :', hits_at_n_score(ranks, 10))","metadata":{"id":"u5YHZs9elojV","execution":{"iopub.status.busy":"2022-12-25T18:39:07.645579Z","iopub.execute_input":"2022-12-25T18:39:07.645993Z","iopub.status.idle":"2022-12-25T18:39:07.658263Z","shell.execute_reply.started":"2022-12-25T18:39:07.645954Z","shell.execute_reply":"2022-12-25T18:39:07.656739Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"hits@1 : 0.4\nhits@3 : 0.5\nhits@5 : 0.5\nhits@10 : 0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"# print unique entities\nprint('Number of unique entities:', len(model.ent_to_idx))","metadata":{"id":"IzvhHy6XIHXI","execution":{"iopub.status.busy":"2022-12-25T18:39:07.660336Z","iopub.execute_input":"2022-12-25T18:39:07.662065Z","iopub.status.idle":"2022-12-25T18:39:07.672131Z","shell.execute_reply.started":"2022-12-25T18:39:07.662006Z","shell.execute_reply":"2022-12-25T18:39:07.670639Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Number of unique entities: 14184\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**What if, for a model, you observe that on a test set, the MRR score is 0.01? Is it a good model?**\n\nIt is not very straightforward. What the above value means is that if you remove the outlier effect, on an average the ranks are around 100 (1/0.01). It may be a good/bad value. It depends on number of corruptions that you have used for the computation. Say you had 1 million corruptions and yet the mrr score was 0.01. The model, in general, was quite good at ranking against 1 million corruption because on an average it gave a rank of close to 100. But say if the corruptions were only 100 and we had an mrr of 0.01, it means that the model did a very bad task at ranking the test triples against just 100 corruptions.\n\nOn a real life dataset, on should take a closer look at **hits@n** values and decide whether the model is a good model or not. ***The choice of n should depend on the number of corruptions that are being generated per test triple***. If a large percentage of ranks computed on the test set triple falls within the n ranks, then the model can be considered as a good model.","metadata":{"id":"EzUfheLiOfwU"}},{"cell_type":"code","source":"def display_aggregate_metrics(ranks):\n    print('Mean Rank:', mr_score(ranks)) \n    print('Mean Reciprocal Rank:', mrr_score(ranks)) \n    print('Hits@1:', hits_at_n_score(ranks, 1))\n    print('Hits@10:', hits_at_n_score(ranks, 10))\n    print('Hits@100:', hits_at_n_score(ranks, 100))\n\n\ndisplay_aggregate_metrics(ranks)\n","metadata":{"id":"GLxF6F1Blxf1","execution":{"iopub.status.busy":"2022-12-25T18:39:07.673413Z","iopub.execute_input":"2022-12-25T18:39:07.673943Z","iopub.status.idle":"2022-12-25T18:39:07.680673Z","shell.execute_reply.started":"2022-12-25T18:39:07.673909Z","shell.execute_reply":"2022-12-25T18:39:07.680054Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Mean Rank: 252.7\nMean Reciprocal Rank: 0.4745306577645\nHits@1: 0.4\nHits@10: 0.7\nHits@100: 0.8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n## 3.4. Training with early stopping\n\nWhile training a model, we would like to make sure that the model does not overfit or under fit on the data. If we train a model for a fixed number of epochs, we will not know whether the model has underfit or overfit the training data. Hence it is necessary to test the model performance on a held out set at regular intervals to decide when to stop training. This is called \"Early stopping\", i.e. we don't let the model run for a long time but stop much before when the performance on the held out set starts to degrade. \n\nHowever we also do not want to model to overfit on the held out set and limit the generalization capabilities of the model. Hence we should create both a validation set and a test set to verify the generalization capability of the model, and to make sure that we dont over fit and under fit on the data.  ","metadata":{"id":"HM0ax6rPpbpe"}},{"cell_type":"code","source":"early_stopping_params = { 'x_valid': X_valid,   # Validation set on which early stopping will be performed\n                          'criteria': 'mrr',    # metric to watch during early stopping\n                          'burn_in': 150,       # Burn in time, i.e. early stopping checks will not be performed till 150 epochs\n                          'check_interval': 50, # After burn in time, early stopping checks will be performed at every 50th epochs (i.e. 150, 200, 250, ...)\n                          'stop_interval': 2,   # If the monitored criteria degrades for these many epochs, the training stops. \n                          'corrupt_side':'s,o'  # Which sides to corrupt furing early stopping evaluation (default both subject and obj as described earlier)\n                        }\n\n# create a model as earlier\nmodel = TransE(k=100, \n               epochs=10000, \n               eta=1, \n               loss='multiclass_nll', \n               initializer='xavier', initializer_params={'uniform': False},\n               regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n               optimizer= 'adam', optimizer_params= {'lr': 0.001}, \n               seed= 0, batches_count= 1, verbose=True)\n\n# call model.fit by passing early stopping params\nmodel.fit(X_train,                                      # training set\n          early_stopping=True,                          # set early stopping to true\n          early_stopping_params=early_stopping_params)  # pass the early stopping params\n\n# evaluate the model with filter\nX_filter = np.concatenate([X_train, X_valid, X_test], 0)\nranks = evaluate_performance(X_test, \n                             model=model, \n                             filter_triples=X_filter)\n# display the metrics\ndisplay_aggregate_metrics(ranks)","metadata":{"id":"DagdzuwspU1Q","execution":{"iopub.status.busy":"2022-12-25T18:39:07.684502Z","iopub.execute_input":"2022-12-25T18:39:07.685031Z","iopub.status.idle":"2022-12-25T18:46:36.894846Z","shell.execute_reply.started":"2022-12-25T18:39:07.684997Z","shell.execute_reply":"2022-12-25T18:46:36.893174Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"WARNING - All triples will be processed in the same batch (batches_count=1). When processing large graphs it is recommended to batch the input knowledge graph instead.\n","output_type":"stream"},{"name":"stderr","text":"Average TransE Loss:   0.016592 — Best validation (mrr): 0.091048:   7%|▋         | 699/10000 [07:16<1:36:42,  1.60epoch/s]\n100%|██████████| 1000/1000 [00:06<00:00, 149.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean Rank: 498.5745\nMean Reciprocal Rank: 0.1617518767663223\nHits@1: 0.0975\nHits@10: 0.2835\nHits@100: 0.5895\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n## Summary so far\n","metadata":{"id":"Ic7r20ScpS78"}},{"cell_type":"code","source":"# ----------------------\n# Generate train/test data\n# create train/test/valid splits, train the model and evaluate using train_test_split_no_unseen API\nfrom ampligraph.evaluation import train_test_split_no_unseen\n# get the validation set of size 500\ntest_train, X_valid = train_test_split_no_unseen(dataset.values, 500, seed=0)\n\n# get the test set of size 1000 from the remaining triples\nX_train, X_test = train_test_split_no_unseen(test_train, 1000, seed=0)\n# ----------------------\n# Training:\n\nprint('Training set:', X_train.shape)\n\n# Train a KGE model\nmodel = TransE(k=300, \n               epochs=100, \n               eta=1, \n               loss='multiclass_nll', \n               initializer='xavier', initializer_params={'uniform': False},\n               regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},\n               optimizer= 'adam', optimizer_params= {'lr': 0.0001}, \n               seed= 0, batches_count= 10, verbose=True)\n\nmodel.fit(X_train)\n# ----------------------\n# Evaluate: \n# Filtered evaluation with ranking strategy assigning worst rank to break ties\n\nfrom ampligraph.utils import save_model, restore_model\nsave_model(model, 'TransE.pkl')\nmodel = restore_model('TransE.pkl')\n\n# create the filter \nX_filter = np.concatenate([X_train, X_valid, X_test], 0)\n\n# compute ranks\nranks = evaluate_performance(X_test, \n                             model=model, \n                             filter_triples=X_filter)\n\n# ranks are computed per triple\nprint('Test set:', X_test.shape)\nprint('Size of ranks:', ranks.shape)\n\n# Aggregate metrics show the aggregate performance of the model on the test set using a single number\ndisplay_aggregate_metrics(ranks)\n# ----------------------","metadata":{"id":"hBXrmiA1lzjO","execution":{"iopub.status.busy":"2022-12-25T18:46:36.897424Z","iopub.execute_input":"2022-12-25T18:46:36.897920Z","iopub.status.idle":"2022-12-25T18:49:32.575332Z","shell.execute_reply.started":"2022-12-25T18:46:36.897870Z","shell.execute_reply":"2022-12-25T18:49:32.574113Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Training set: (308579, 3)\n","output_type":"stream"},{"name":"stderr","text":"Average TransE Loss:   0.057380: 100%|██████████| 100/100 [02:32<00:00,  1.52s/epoch]\n100%|██████████| 1000/1000 [00:15<00:00, 63.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: (1000, 3)\nSize of ranks: (1000, 2)\nMean Rank: 628.823\nMean Reciprocal Rank: 0.17737131070343667\nHits@1: 0.1155\nHits@10: 0.296\nHits@100: 0.5545\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Key Takeaways**\n- `train_test_split_no_unseen` API can be used to generate train/test splits such that test set contains only entities 'seen' during training\n- Once a model is trained, one can use `model.predict` to choose from a set of hypothesis based on the scores returned by the model.\n- One can access the quality of model on a **test set of True Facts** by using metrics such as MR, MRR and hits@n\n- We can use early stopping to prevent model from over/under fitting by using a Validation Set.","metadata":{"id":"gP2K-mHgQ54K"}},{"cell_type":"markdown","source":"---\n# 4. Knowledge Discovery \n\nIn Ampligraph we provide a number of high-level convenience functions for performing knowledge discovery using graph embeddings:\n\n> ***query_topn***: which when given two elements of a triple will return the top_n results of all possible completions ordered by predicted score.\n\n> ***discover_facts***: generate a set of candidate statements using one of several defined strategies and return triples that perform well when evaluated against corruptions.\n\n> ***find_clusters***: perform link-based cluster analysis on graph embeddings.\n\n> ***find_duplicates***: which will find duplicate entities in a graph based on their embeddings.\n\n","metadata":{"id":"pdX1lwK4rX_Y"}},{"cell_type":"markdown","source":"## 4.1 Triple completion\n\nSometimes you may have either a relation and entity (head or tail) pair, or just two entities, and you want to see what the top n results returned by the model are that completes the triple. \n\n``` \n    <head, relation, ?> \n    <head, ?,        tail>\n    <?,    relation, tail>\n```\n\nSpecify ```rels_to_consider``` or ```ents_to_consider``` lists to return triples where the missing element is filled only from that list. \n","metadata":{"id":"N3dmkTgHrdB0"}},{"cell_type":"code","source":"from ampligraph.discovery import query_topn\n\n# restore the previously saved model to save time\nmodel = restore_model('TransE.pkl')\n\ntriples, scores = query_topn(model, top_n=5, \n                             head='missy elliott', \n                             relation='/people/person/profession', \n                             tail=None, \n                             ents_to_consider=None, \n                             rels_to_consider=None)\n\nfor triple, score in zip(triples, scores):\n    print('Score: {} \\t {} '.format(score, triple))","metadata":{"id":"7U1Wur_hravz","execution":{"iopub.status.busy":"2022-12-25T19:18:11.992159Z","iopub.execute_input":"2022-12-25T19:18:11.992561Z","iopub.status.idle":"2022-12-25T19:18:12.186756Z","shell.execute_reply.started":"2022-12-25T19:18:11.992530Z","shell.execute_reply":"2022-12-25T19:18:12.186006Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Score: -9.723002433776855 \t ['missy elliott' '/people/person/profession' 'pianist'] \nScore: -9.753883361816406 \t ['missy elliott' '/people/person/profession' 'songwriter'] \nScore: -10.130367279052734 \t ['missy elliott' '/people/person/profession' 'bandleader'] \nScore: -10.205233573913574 \t ['missy elliott' '/people/person/profession' 'musician'] \nScore: -10.212827682495117 \t ['missy elliott' '/people/person/profession' 'record producer'] \n","output_type":"stream"}]},{"cell_type":"code","source":"triples, scores = query_topn(model, top_n=10, \n                             head='the departed', \n                             relation=None, \n                             tail='/m/086k8', \n                             ents_to_consider=None, \n                             rels_to_consider=None)\n\nfor triple, score in zip(triples, scores):\n    print('Score: {} \\t {} '.format(score, triple))","metadata":{"id":"6i8J-rFvIPuB","execution":{"iopub.status.busy":"2022-12-25T18:49:32.753555Z","iopub.execute_input":"2022-12-25T18:49:32.753870Z","iopub.status.idle":"2022-12-25T18:49:32.871193Z","shell.execute_reply.started":"2022-12-25T18:49:32.753841Z","shell.execute_reply":"2022-12-25T18:49:32.869219Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Score: -7.142705917358398 \t ['the departed' '/film/film/production_companies' '/m/086k8'] \nScore: -7.308218955993652 \t ['the departed'\n '/award/award_winning_work/awards_won./award/award_honor/award_winner'\n '/m/086k8'] \nScore: -7.619558334350586 \t ['the departed' '/location/hud_county_place/place' '/m/086k8'] \nScore: -7.763204097747803 \t ['the departed' '/education/educational_institution/campuses' '/m/086k8'] \nScore: -7.870114803314209 \t ['the departed'\n '/education/educational_institution_campus/educational_institution'\n '/m/086k8'] \nScore: -8.225320816040039 \t ['the departed' '/film/film/produced_by' '/m/086k8'] \nScore: -8.238903045654297 \t ['the departed' '/film/film/written_by' '/m/086k8'] \nScore: -8.325393676757812 \t ['the departed'\n '/celebrities/celebrity/sexual_relationships./celebrities/romantic_relationship/celebrity'\n '/m/086k8'] \nScore: -8.459305763244629 \t ['the departed'\n '/base/popstra/celebrity/dated./base/popstra/dated/participant'\n '/m/086k8'] \nScore: -8.486371994018555 \t ['the departed'\n '/award/award_nominated_work/award_nominations./award/award_nomination/nominated_for'\n '/m/086k8'] \n","output_type":"stream"}]},{"cell_type":"code","source":"from ampligraph.discovery import query_topn\n\n# restore the previously saved model to save time\nmodel = restore_model('TransE.pkl')\n\ntriples, scores = query_topn(model, top_n=5, \n                             head=None, \n                             relation='/people/person/profession', \n                             tail='musician', \n                             ents_to_consider=None, \n                             rels_to_consider=None)\n\nfor triple, score in zip(triples, scores):\n    print('Score: {} \\t {} '.format(score, triple))","metadata":{"execution":{"iopub.status.busy":"2022-12-25T19:22:17.084477Z","iopub.execute_input":"2022-12-25T19:22:17.084913Z","iopub.status.idle":"2022-12-25T19:22:17.327536Z","shell.execute_reply.started":"2022-12-25T19:22:17.084874Z","shell.execute_reply":"2022-12-25T19:22:17.326474Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Score: -7.596163272857666 \t ['bill wyman' '/people/person/profession' 'musician'] \nScore: -7.59886360168457 \t ['pete townshend' '/people/person/profession' 'musician'] \nScore: -7.616781711578369 \t ['paul weller' '/people/person/profession' 'musician'] \nScore: -7.62177038192749 \t ['tori amos' '/people/person/profession' 'musician'] \nScore: -7.725285053253174 \t ['steve winwood' '/people/person/profession' 'musician'] \n","output_type":"stream"}]}]}